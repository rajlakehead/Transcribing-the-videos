{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "In this Project, you will bring together many of the tools and techniques that you have learned throughout this course into a final project. You can choose from many different paths to get to the solution. \n",
    "\n",
    "### Business scenario\n",
    "\n",
    "You work for a training organization that recently developed an introductory course about machine learning (ML). The course includes more than 40 videos that cover a broad range of ML topics. You have been asked to create an application that will students can use to quickly locate and view video content by searching for topics and key phrases.\n",
    "\n",
    "You have downloaded all of the videos to an Amazon Simple Storage Service (Amazon S3) bucket. Your assignment is to produce a dashboard that meets your supervisorâ€™s requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project steps\n",
    "\n",
    "To complete this project, you will follow these steps:\n",
    "\n",
    "1. [Viewing the video files](#1.-Viewing-the-video-files)\n",
    "2. [Transcribing the videos](#2.-Transcribing-the-videos)\n",
    "3. [Normalizing the text](#3.-Normalizing-the-text)\n",
    "4. [Extracting key phrases and topics](#4.-Extracting-key-phrases-and-topics)\n",
    "5. [Creating the dashboard](#5.-Creating-the-dashboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful information\n",
    "\n",
    "The following cell contains some information that might be useful as you complete this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"c56161a939430l3396553t1w744137092661-labbucket-rn642jaq01e9\"\n",
    "job_data_access_role = 'arn:aws:iam::744137092661:role/service-role/c56161a939430l3396553t1w7-ComprehendDataAccessRole-1P24MSS91ADHP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp s3://aws-tc-largeobjects/CUR-TF-200-ACMNLP-1/video/ . --recursive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Viewing the video files\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source video files are located in the following shared Amazon Simple Storage Service (Amazon S3) bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import speech_recognition as sr \n",
    "from pydub.utils import make_chunks\n",
    "from tqdm import tqdm\n",
    "from pydub import AudioSegment \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transcribing the videos\n",
    " ([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to implement your solution to transcribe the videos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoFiles = [] \n",
    "for file in os.listdir('./videos/'):\n",
    "    if file.endswith('.mp4'):\n",
    "        videoFiles.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total videos- 46\n"
     ]
    }
   ],
   "source": [
    "print(\"Total videos-\",len(videoFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer/code here\n",
    "# Loading video files\n",
    "for file in videoFiles:      \n",
    "    video = AudioSegment.from_file(f'videos/{file}', format=\"mp4\")\n",
    "    audio = video.set_channels(1).set_frame_rate(16000).set_sample_width(2)\n",
    "    audio_filename= file[:-4]+'.wav'\n",
    "    audio.export(f'audios/{audio_filename}', format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioFiles = []\n",
    "for file in os.listdir('./audios/'):\n",
    "    if file.endswith('.wav'):\n",
    "        audioFiles.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total audio files- 46\n"
     ]
    }
   ],
   "source": [
    "print(\"Total audio files-\",len(audioFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ = []\n",
    "#count = 0\n",
    "for file in audioFiles:\n",
    "    myaudio = AudioSegment.from_wav(f'./audios/{file}')\n",
    "    chunks_length = 35000\n",
    "    chunks = make_chunks(myaudio,chunks_length)\n",
    "    text = \"\"\n",
    "    for j, chunk in enumerate(chunks):\n",
    "        chunkName = f\"{file[:-4]}_{j}.wav\"\n",
    "        chunk.export(f\"./chunkedAudios/{chunkName}\",format = \"wav\")\n",
    "        r = sr.Recognizer()\n",
    "        with sr.AudioFile(f\"./chunkedAudios/{chunkName}\") as source:\n",
    "            audio_data = r.record(source)\n",
    "            try:\n",
    "                temp = r.recognize_google(audio_data)\n",
    "                text = text + \" \" + temp\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Got UnknownValeError\")\n",
    "    data = [file,text]\n",
    "    text_.append(data)\n",
    "    #count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in text_:\n",
    "    filename = i[0][:-4]+\".txt\"\n",
    "    with open(f'./Transcribed_files/{filename}','w') as writer:\n",
    "        writer.write(i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalizing the text\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to perform any text normalization steps that are necessary for your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer/code here\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Raj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Raj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Raj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = text.strip()\n",
    "    \n",
    "    text = re.sub('\\s+', ' ', text) \n",
    "\n",
    "    intro_phrases = ['hi', 'hello', 'welcome', 'thanks', 'watching', 'video']\n",
    "\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word.isalpha()]\n",
    "\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    stop_words = stop_words + intro_phrases\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Lemmatize words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    preprocessedSentences = ' '.join(words)\n",
    "\n",
    "    return preprocessedSentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = []\n",
    "\n",
    "for file, transcript in text_:\n",
    "    transcripts.append([f\"{file[:-4]}.mp4\", preprocess_text(transcript)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mod01_Course Overview.mp4',\n",
       "  'amazon academy machine learning foundation module learn course objective various job role machine learning domain go learn machine learning completing module able identify course prerequisite objective indicate role data scientist business identify resource learning going look prerequisite taking course take course recommend first complete aws academy cloud foundation also general technical knowledge including foundational computer literacy skill like basic computer concept email file management good understanding internet also recommend intermediate skill python programming general knowledge applied statistic finally general business knowledge important course includes insight information technology used business also important business related skill set communication skill leadership skill orientation towards customer service course introduced key concept machine learning tool us also introduced work aws service machine learning learn recognize machine learning deep learning part artificial intelligence describe official intelligence machine learning terminology identify machine learning used solve business problem describe machine learning process list tool available data scientist identify use machine learning instead traditional software development method part course also learn implement machine learning pipeline includes formulate problem business request obtain secure data machine learning build jupiter notebook using amazon sage maker outline process evaluating data explain data need preprocessed use open source tool examine preprocess data also use amazon sage maker train host machine learning model use cross validation test performance machine learning model use hosted model inference create amazon sage maker hyper tuning job optimize model effectiveness finally use managed amazon machine learning service solve specific machine learning problem forecasting computer vision natural language processing review course outline achieve course objective complete following module start module get introduction machine learning module learn implement machine learning pipeline amazon sagemaker modu four five six describe apply managed amazon machine learning service problem forecasting computer vision natural language processing finally module summary course also includes overview step take work towards aws certified machine learning specialty next five slide provide detail sub topic covered module purpose module introduce major concept understand machine learning section describes overall field machine learning machine learning relates artificial intelligence deep learning section learn common business problem solve machine learning section describes general workflow solving machine learning problem also learn common machine learning term section review commonly used tool machine learning professional lastly section get overview common challenge face working machine learning problem module get introduction amazon sagemaker use implement machine learning pipeline module focus application machine learning solve problem several public domain data set example machine learning pipeline section introduces defining business problem data set use module section find phase machine learning pipeline using computer vision example application section learn collect secure data section describes different technique evaluating data section learn process feature engineering section describes step take train model sagemaker section get overview option sagemaker hosting using model finally section cover evaluate tune model sagemaker module introduced using machine learning create forecast based time series data section introduced forecasting common application section outline pitfall using time series data make forecast finally section get overview use amazon forecast module learn using machine thing computer vision section describes general problem solve computer vision section learn process analyzing image video section learn step need take prepare data set computer vision module introduced natural language processing machine learning section learn general set problem solve natural language processing section review amazon machine learning service use address natural language processing problem service include amazon transcribe amazon translate amazon lex amazon comprehend amazon poly module final module course module review learned throughout course also introduced next step take want achieve aws certified machine learning specialty section one module summarizes topic covered course section learn aws documentation also review two common framework applying aws service finally section describes step take want continue working towards aws certified machine learning specialty section learn common job role machine learning professional interested data scientist role focus developing analytical statistical programming skill data scientist use skill collect analyze interpret large data set university offer degree data science data scientist often degree related field like statistic math computer science economics data scientist need technical competency statistic machine learning programming language data analytics like career learning engineer skill need similar data scientist skill set like data scientist machine learning engineer also require technical competency statistic machine learning however focus programming skill software architecture analysis interpretation machine learning engineer apply programming architecture skill design develop machine learning system machine learning engineer often previous experience software development rely heavily programming software engineering machine learning role might also interested career science apply machine learning technology field machine learning impact everything astronomy zoology many different path open applied science researcher primary focus type science working need skill data scientist also need know apply skill chosen domain thus applied science rule also require technical competency machine learning many software developer integrating machine learning application interested career software developer also include machine learning technology study machine learning developer primary focus software development skill also need skill data scientist make sure take coursework statistic applied mathematics final note module recommend reviewing student guide student find link documentation resource use throughout course introduction see next'],\n",
       " ['Mod02_Intro.mp4',\n",
       "  'module aws academy machine learning module going introduce machine learning well first look business problem solved machine learning well talk terminology process tool challenge face completing module able recognize machine learning deep learning part artificial intelligence describe artificial machine learning terminology identify machine learning used solve business problem describe machine learning process list tool available data scientist identify use machine learning instead traditional software development method ready get started section see next'],\n",
       " ['Mod02_Sect01.mp4',\n",
       "  'section section going talk machine learning course introduction machine learning also known ml first discus machine learning fit larger picture machine learning subset artificial intelligence ai broad branch computer science focused building machine human task deep learning domain machine learning understand fit together discus one mentioned machine learning subset broader computer science field known artificial intelligence ai focus building machine perform task human would typically perform contemporary popular culture probably seen ai movie television work fiction example might seen ai control world around start acting initiative hey started computer agent perceive environment take action achieve specific goal maybe outcome creator originally wished fictional ai interact extensively human helper worker generally better job working humanity general purpose kind ai example artificial general intelligence agi capacity learn understand task human ai problem typically span many field research natural language processing reasoning knowledge representation learning perception physical environment interaction ai yet reality u unless truly living simulation every year move closer area might also read seen commentary ethic creating ai view positive perhaps partly fear malicious fictional ai want destroy humanity use power source perhaps concerned risk mass unemployment intelligent machine could work need break worry though going build next rogue ai course maybe next one search probably find many definition machine learning universally agreed upon definition start looking couple definition example could say machine learning scientific study algorithm statistical model task using inference instead instruction bad starting point key point using algorithm statistical model instead instruction help better understand apply idea concrete example suppose need write application determines email message spam without machine learning need write complex series decision statement using else statement also need use word subject body number link length message determine email message spam would hard labor intensive build large set rule covering every possibility machine learning however could use list email message marked spam spam train machine learning model model would learn pattern word length attribute good indicator spam message presented model email message seen model would perform prediction say whether message spam spam deep learning represents significant leap forward capability artificial intelligence machine learning theory behind deep learning created human brain work artificial neural network end inspired biological neuron found brain although implementation become different artificial neuron one input single output neuron fire activate output based transformation input neural network composed layer artificial neuron connection layer typically hidden layer network output single neuron connects input neuron next layer network asked solve problem input layer populated training data neuron activate throughout layer answer presented output layer accuracy output measured meet threshold training repeated slight change weight connection neuron neural network repeatedly time strengthens connection lead success diminishes connection lead failure see course machine learning practitioner spend lot time optimizing ml model selecting best data feature train selecting model best result contrast deep learning practitioner spend almost time instead spend time modeling data different architecture though theory deep learning go back decade hardware needed run deep learning problem generally accessible recently available use deep learning address problem complex problem could worked mainstream machine learning recent occurrence rapid advancement machine deep learning started around partly law rise cloud computing resulted easier access larger faster cheaper compute storage capability rent computing power hour penny needed substantial investment buy operate large scale compute cluster neural network started used imagenet visual recognition challenge machine learning competition image recognition accuracy rate jumped steadily climbing ever since fact exceeded human performance key takeaway section first artificial intelligence broad field building machine perform human task also machine learning subset ai focus using data train machine learning model make prediction deep learning technique inspired human biology us layer artificial neuron build network dissolve problem last advancement technology cloud computing algorithm development led corresponding advance machine learning capability application section see next'],\n",
       " ['Mod02_Sect02.mp4',\n",
       "  'back section going look type business problem machine learning help solve machine learning used across digital life email spam filter result machine learning program trained example spam regular email message based book reading product bought machine learning program predict book product likely interested machine learning program train data reader habit purchase detecting credit card fraud machine learning program trained example transaction turned fraud along normal transaction probably think many example social medium application using facial detection group photo detecting brain tumor brain scan finding anomaly three main type machine learning supervised learning model us known input output generalize future output unsupervised learning model know input output find pattern data without help reinforcement learning model interacts environment learns take action maximize reward important know different type ml type guide towards selecting algorithm make sense solving business problem let look type supervised learning popular ml widely applicable called supervised learning need supervisor teacher show right answer speak like student supervised algorithm need learn example essentially need teacher us training data help determine pattern relationship input output want build application detect credit card fraud need training data includes example fraud example normal transaction within supervised learning different type problem classification regression two subtypes classification problem first binary classification think back example identifying fraudulent transaction target variable example limited two option fraudulent fraudulent binary classification problem also multiclass classification problem ml problem classify observation three category say ml model predicts customer calling store reduce number transfer needed customer get correct customer support department case different customer support department represent variety potential target variable could many different department much two also regression problem regression problem longer mapping input defined number category instead wrapping input continuous value like integer one example ml regression problem predicting price company stock computer vision good example supervised learning cat dog tumor computer vision often built deep learning model automates extraction analysis classification understanding useful information single image sequence image computer vision naples machine identify people place thing image accuracy human level greater speed efficiency image data take many form single image sequence view multiple camera data learn computer vision later course well discus unsupervised machine learning sometimes data supervisor room unsupervised learning label provided like supervised learning know variable pattern instance machine uncover create label model use data presented detect emerging property entire data set construct pattern property clustering common subcategory unsupervised learning kind algorithm group data different cluster based similar feature better understand specific cluster example analyzing customer purchasing habit unsupervised algorithm identify group customer associated size tier company advantage unsupervised algorithm enable see pattern data aware natural language processing also known nlp another area machine learning experiencing growth ever used alexa voice assistant use nlp answer question nlp speech also written text nlp show many application example nlp used chat call center bot automated system help get bank balance order food restaurant use nlp translation tool convert text language example might use application translate menu real time nlp also used voice text translation convert spoken word text finally nlp used sentiment analysis use analyze sentiment comment review product music movie sentiment could used give movie audience rating learn nlp later course another kind machine learning gaining popularity recently reinforcement learning unlike machine learning reinforcement learning continuously improves model mining feedback previous iteration reinforcement learning agent continuously learns trial error interacts environment reinforcement learning broadly useful reward desired outcome known path achieving path requires lot trial error discover take example aws deep racer aws deep racer simulator agent virtual car environment virtual race track action throttle steering input car goal completing racetrack quickly possible without deviating track car need learn desired driving behavior reach goal completing track car learn aws deep racer team use reward incentivize model learn desire driving behavior reinforcement learning thing driving learning called agent case aws deep racer car environment place agent learns example would marked race track agent something environment provokes response crossing boundary cross called action response called reward penalty depending whether agent something reinforced discouraged model agent move within environment action start receiving reward fewer penalty meet desired business outcome vehicle bring together many deep learning algorithm model solve problem driving point point b two main task continuous detection environment forecasting change involve detecting object localizing predicting movement detected object output finding act input system make decision vehicle various control use case vehicle require response environment example previously hidden pedestrian walk behind obstacle vehicle break need applied immediately latency room air action every problem solved machine learning sometimes regular programming work well need interested exploring potential machine learning solution look existence large data set large number variable machine learning often best choice uncertain business logic procedure need obtain answer accomplish task machine learning system complex supporting infrastructure management support technical expertise need place help ensure project success key takeaway section explored machine learning application already part everyday life first machine learning problem grouped three category supervised learning training data already know answer unsupervised learning data looking insight within data reinforcement learning model learns based experience feedback business problem supervised learning problem section see next'],\n",
       " ['Mod02_Sect03.mp4',\n",
       "  'back section going give quick overview machine learning terminology typical workflow cover topic detail later course focus larger picture begin always start business problem team believe could benefit machine learning want problem formulation phase one task articulate business problem convert ml problem formulated problem move data preparation preprocessing phase pull data one data source data source might difference data type need reconciled form single cohesive view data need visualize data use statistic determine data consistent used machine learning well look data source later course example data four column containing data three different data source source slightly different way representing data result shown table ml problem column represent feature row represent instance issue data instance case need subject matter expert functional expert understand authenticity data example date represented could november february year someone owns manages data pool would able clarify ambiguity also word male probably attributed import issue cell shifted position could outside chance actual location molly city capital republic maldives time error identification simple need sme review data learn role expert later course remember one largest impact success machine learning project consistent correct data data good shape time train model process get iterative fluid likely go many multiple pass feature engineering training evaluating tuning find model meet business goal feature engineering process selecting creating feature model trained feature column data data set goal model correctly estimate target value new data ml algorithm use feature predict target example target data average number step taken week selecting correct feature involve adding removing calculating new feature might want make data format consistent consistent format could later used model make change cosmetic reason depending problem want solve data might even need include name feature example data country feature traditional database might want move country lookup table reference ml algorithm want data instance single row ml algorithm need numerical data process could consider turning country text country iso code however model might interpret numer value meaning uk iso code value would significant iso code value u case splitting data multiple column fine known categorical encoding learn later course type data could convert text value numerical value example could use zero one represent male female numeric value used easily model painting feature like age birth month shown bm table day week shown w extracting age birth month day week might appropriate depending problem trying solve age impact target variable day week born worry sound complicated learn feature engineering later course data cleaned identified feature want use time train model wo use data train model fact need hold data data test typically use data train save rest data testing next train model training data diagram model us xgboost algorithm model parameter set parameter alter algorithm work known hyperparameters output training job trained model use test data see well model performs take instance model seen use perform prediction already know target test data compare two value comparison calculate metric give data well model performing make change model data feature hyperparameters find model yield best result training real danger overfitting underfitting model model overfitting training data see model performs well training data perform well evaluation data model memorizing data saw ca generalize unseen example model underfitting training data model performs poorly training data model ca capture relationship input example often called x target value often called understanding model fit important understanding root cause poor model accuracy understanding guide take corrective step determine whether predictive model underfitting overfitting training data looking prediction error training data evaluation data show step take avoid later course retrained model satisfied result deploy model deliver best possible prediction later course walk different phase give experience knowing process also useful using managed service also explore later certain amazon ml service bulk work key takeaway section first looked machine learning pipeline process guide process training evaluating model iterative process broken three broad step data processing model model evaluation see next one'],\n",
       " ['Mod02_Sect04.mp4',\n",
       "  'back section look tool using throughout rest course start list exhaustive list tool available today going cover high level good place get started first jupiter notebook jupiter notebook open source web application use create share document contain live code equation visualization narrative text us food data cleaning transformation numerical simulation statistical modeling data visualization machine learning much jupiter lab interactive development environment jupiter notebook code data jupiter lab flexible use configure arrange user interface support wide range workflow data science scientific computing machine learning jupiterlab extensible modular write plugins add new component integrate existing one later course use amazon sage maker host jupiter notebook jupiter lab panda open source python library used data handling analysis panda represents data table similar spreadsheet table known panda dataframe matplotlib python library creating scientific static animated interactive visualization python use generate plot data later course seaborn another data visualization library python built matplotlib provides high level interface drawing attractive informative statistical graph numpy one fundamental scientific computing package python contains function n dimensional array object also useful math function linear algebra transform random number capability scient open source machine learning library support supervised unsupervised learning also provides various tool model fitting data preprocessing model selection evaluation many utility scientific learn built numpy psy pie matplotlib good tool exploring machine learning although use borrow function course might want consider exploring complete score moving individual package also tool contain framework already mentioned sidekit learn good library machine learning framework supported aws tensorflow kera also include library use machine learning framework listed supported aws used amazon sagemaker aws also provides compute instance tuned machine learning cloud edge compute instance optimized learning inference another aws resource use certain amazon machine image amis offer amis contain many popular framework finally amazon sage maker aws service many capability first sagemaker deploy machine learning instance running jupiter notebook jupiter lab manages deployment compute resource need connect jupiter environment sagemaker also provides tool labeling data training model hosting trained model aws marketplace also provides selection model package algorithm machine learning developer aws also provides set management machine learning service integrate application even substantial machine learning experience computer vision amazon recognition provides object facial recognition image also amazon extract text image speech service include amazon poly speak text another speech service amazon transcribe convert spoken audio text language amazon comprehend us nlp find insight relationship text also amazon translate translate text different language want work chatbots amazon lex help build interactive conversational application use voice text forecasting amazon forecast us machine learning combine time series data additional variable build forecast finally like work recommendation amazon personalized help create individual personalized recommendation customer managed service already trained many aspect problem domain need provide specific data get started going look many managed service second half course learn thing takeaway section include point first python popular language performing machine learning task jupiter notebook provide hosted development environment machine learning use jupiter notebook frequently machine learning large number open source tool panda use often machine learning practitioner finally depending upon requirement might start framework create solution might also use tool amazon sagemaker help heavy lifting could simply use adapt one managed amazon ml service specific problem domain see next one'],\n",
       " ['Mod02_Sect05.mp4',\n",
       "  'back section going discus challenge machine learning come across many challenge machine learning lot poor quality inconsistent data available significant portion job getting access generating enough good data representative problem want solve key issue watch overfitting model data although mostly data science experience staffing team data scientist management support using machine learning business landscape look like problem complex formulate machine learning problem resulting model explained business ca explained might get adopted cost building updating operating machine learning solution finally technology map business unit access data needed data secured meet regulatory requirement tool framework used solution integrate system important question successful need able answer address many machine learning problem solved today using existing model without substantial machine learning knowledge already talked aws managed service machine learning add sophisticated machine learning capability application basic develop skill calling apis model use adapt one example yolo mean look yolo popular computer vision model addition scenario use aws marketplace prefer buy model service independent software vendor instead developing key takeaway section first face many machine learning challenge biggest one directly influence related data consider managed service solve machine learning problem within domain support using amazon recognition computer vision problem section see next'],\n",
       " ['Mod02_WrapUp.mp4',\n",
       "  'time review module main takeaway module first looked defining machine learning fit broader ai landscape also looked type problem machine learning help u solve machine learning applies learning algorithm develop model large data set looked machine learning pipeline different stage developing machine learning application finally introduced tool service use discussing challenge machine learning summary module learned recognize machine learning deep learning part artificial intelligence describe artificial intelligence machine learning terminology identify machine learning used solve business problem describe machine learning process list tool available data scientist identify use machine learning instead traditional software development method see next'],\n",
       " ['Mod03_Intro.mp4',\n",
       "  'back aws academy machine learning module going work entire machine learning pipeline using amazon sage maker module discus typical process handling machine learning problem machine learning pipeline applied many machine learning problem focus supervised learning process learn module adapted type machine learning well large module covering lot material end module able formulate problem business request obtain secure data machine learning build jupiter notebook using amazon sagemaker outline process evaluating data explain data need preprocessed use open source tool examine preprocess data use amazon sagemaker host machine learning model use cross validation test performance machine learning model use hosted model inference finally create amazon sagemaker hyperparameter tuning job optimize model effectiveness ready get started see next'],\n",
       " ['Mod03_Sect01.mp4',\n",
       "  'back module section going take look data set use module also look guidance formulate business problem get started reminder machine learning pipeline looked previous module map section module section section cover formulate problem also cover dat use throughout module section discus obtain secure data machine learning activity section show tool technique gaining understanding data section look data ready train model section cover selecting training appropriate machine learning model section show deploy model make prediction section examine process evaluating performance machine learning model finally section look tuning model machine learning pipeline iterative process work real world problem might find iterating many time arrive solution meet business need first section examine think turning business requirement machine learning problem first step phase simply define problem want solve goal want reach understanding business goal key use measure performance solution unusual solidify business problem begin targeting solution lot question could ask develop good understanding problem information problem begin framing approach first problem even solved machine learning would traditional approach make sense supervised unsupervised machine learning problem labeled data train supervised model many question could ask business ultimately try validate use machine learning make sure access right people data also try come simplest solution problem example identify fraudulent credit card transaction stop transaction process problem business goal outcome driving problem statement case say intended outcome reduction number customer end membership credit card result fraudulent transaction business perspective define success given problem desired outcome stage need move qualitative statement quantitative statement easily measured continuing example metric could use define success problem might reduction number customer file claim fraudulent transaction within period defined business side problem time start thinking term machine learning model actual output want see model want specific statement reflects ml model actually output example might model output whether credit card transaction fraudulent fraudulent know want ml model actually achieve use information determine type ml working historical data customer filed report fraud transaction use data machine learning purpose historical data fall supervised learning approach label already defined recall earlier course supervised ml type categorized two group classification regression credit card example desired output categorizing transaction fraud fraud see dealing binary classification problem throughout module see several data set used access data set many uc irvine machine learning repository first data set contains numerical information composition wine along quality wine question might want ask data set based composition wine could predict quality therefore price addition question also use data set view statistic deal outlier scale numerical data second data set car evaluation database data set heavily enables explore encoding categorical data convert text value number processed machine learning third data set biomedical data set also use lab question answer data set based biomechanical feature predict patient abnormality data set take entire end end process end trained model tuned use make prediction section looked business problem need converted ml problem also looked key question ask defining success measure outcome impact solution implemented business problem fall one two category first category classification binary ask target belong class second category regression ask predict numerical value section see next'],\n",
       " ['Mod03_Sect02_part1.mp4',\n",
       "  'back going look way collect secure data section explore technique challenge associated collecting securing data needed machine learning consider original example predicting credit card fraud formulated problem data need actually train model get desired output subsequently achieve intended business outcome access data much data solution use bring data one centralized repository answer question essential stage good news budding data scientist many place obtain data private data existing customer already exists including everything log file customary invoice database private data useful depending problem trying solve many case private data found many different system look bring source together shortly sometimes want use data collected made available commercial organization company reuters change healthcare dun bradstreet foursquare maintain database subscribe include curated news story anonymized healthcare transaction global business record location data supplement data commercial data get useful insight would gotten otherwise also many open source data set ranging wine quality movie review data set made available use research teaching purpose aws kaggle uci machine learning repository good place find open source data set government health organization source data could useful supervised machine learning problem need lot data also called observation already need know target answer prediction data kind data already know target answer prediction called labeled data observation data made two element target feature target answer want predict credit card transaction example target given observation either fraud fraud feature attribute example use identify pattern predicting target answer feature credit card example could date transaction vendor amount dollar transaction might wonder source target fraud fraud typically information discovered transaction complete actual card owner notice fraudulent transaction statement information would recorded transaction exactly purpose using train future model given know element ml data set return one original question data need actually train model reach desired output subsequently intended business outcome example stage ml pipeline crucial get domain expertise help answer question domain knowledge start determining feature target data model need make accurate prediction data representative data using model make pre example want predict credit card fraud need collect data positive fraudulent transaction also need collect data negative non fraudulent transaction need type data machine learning algorithm find pattern distinguish two type suppose average amount fraudulent transaction actually training data set includes small fraction fraudulent observation say case difficult model truly learn pattern related fraudulent transaction might encounter production many different service aws could find store data key service might use amazon simple storage service also known amazon provides object level storage store much data want form object think file could csv file file format need access aws management console also access programmatically api sdks solution also use api sdks training data already planning run training job several time different algorithm parameter could use amazon fsx luster file system service speed training job serving data amazon sagemaker high speed first time run training fsx luster automatically copy data make available sagemaker use amazon fsx file system subsequent iteration training job prevents repeated downloads common object alternatively training data might already amazon elastic file system amazon efs recommend using efs data source training data launch training job directly service without needing data movement result faster training start time often case environment data scientist home directory amazon efs quickly iterate model bringing new data sharing data colleague experimenting different field label data set example data scientist use jupiter notebook initial cleansing training set launch training job amazon sagemaker could use jupiter notebook drop column relaunch training job finally compare resulting model see one work better many aws service resource might find data example could use amazon relational database service amazon rds manage relational database service also use amazon redshift manage data warehouse service another option amazon time stream managed time series database design specifically handle large amount data internet thing iot could even spin instance amazon elastic compute cloud also known amazon host database instance data source need extract useful data source assembling data machine learning look next part one section see part two review extract transform load data'],\n",
       " ['Mod03_Sect02_part2.mp4',\n",
       "  'back continue exploring data collection reviewing extract transform load data data typically spread across many different system data provider present challenge need bring data source together something consumed machine learning model extract transform load also known etl step etl defined way extract step pull data source single location extraction might need modify data combine matching record task transform data finally load step data loaded repository amazon typical etl framework several component example consider diagram first crawler program connects data store source target progress ranked list classifier determine schema data creates metadata table aws glue data catalog job defines business logic needed perform etl work run job need use schedule event final note service discussed exist transform partition etl process aws glue fully managed etl service make simple cost effective categorize data clean reach move reliably various data store aws glue consists central metadata repository known aws glue data catalog etl engine automatically generates python scala code also provides flexible scheduler handle dependency resolution job monitoring retries aws glue serverless need set manage infrastructure use aws glue console discover data transform make available search inquiry console call underlying service orchestrate work needed transform data also use aws glue api operation interface aws glue service way edit debug test python scala apache spark etl code using familiar development environment aws glue rooted machine learning receive label data used training example say provide aws glue training data teach model duplicate record data source look like aws glue identify duplicate present analysis data engineer aws glue enables orchestration complex etl job example aws glue crawl data source present information client data catalog aws glue run etl job based event getting new data set example use aws lambda function trigger etl job run soon new data becomes available amazon also register new data set aws glue data catalog part etl job although manage tool available aws manipulate data data scientist also write script jupyter notebook handle data full extract load script shown import variable section import library used note moto library aws variable also set zip file web location local folder extraction download extract section make web request saving bite url stream stream passed zip file function used extract data extracted file folder upload section enumerates folder file uploads file amazon discover script used often migrated standalone function imported python application part two section see part three review secure data'],\n",
       " ['Mod03_Sect02_part3.mp4',\n",
       "  'back continue exploring data collection reviewing secure data important consider security data though data set used course public real data customer transaction health record need kept secure use aws identity access management also known service control access resource make sure securing data aws correctly avoid data breach diagram show simple iam policy allows read access specific bucket listed roll addition controlling access data need make sure data secure good practice might also legally required certain data type financial data health care record aws provides encryption feature storage service typically data rest transit often meet encryption requirement enabling encryption object service want protect data transit must use secure transport like secure socket layer transport layer security ssl tl another aspect consider compliance audit dealing data regulated industry often need audit access data aws cloud trail service enables governance compliance operational auditing risk auditing aws account cloud trail log continuously monitor retain account activity related action across entire aws infrastructure cloud trail provides event history aws account activity including action taken aws management console aws sdks command line tool aws service event history simplifies security analysis resource change tracking troubleshooting also use cloud detect unusual activity aws account feature help simplify operational analysis troubleshooting key takeaway section looked first step solving machine learning problem obtaining data required train machine learning model also reviewed etl used obtain data multiple source service like aws glue make easy obtain data multiple data store finally make sure understand security requirement based business need regulatory requirement also make sure data secure authorized user able access data encrypted possible section see next'],\n",
       " ['Mod03_Sect03_part1.mp4',\n",
       "  'back section going cover evaluate data section look different data format type also look visualize analyze data feature engineering start running statistic data better understand working need ensure right format analysis amazon sage maker algorithm support training data psv format many tool use explore visualize analyze data also read csv format generally speaking need least domain knowledge problem trying solve machine learning example developing model predict set symptom indicates disease need know relationship symptom disease data typically need numeric form machine learning algorithm use data make prediction look way text data next section explore data try gain insight overall data set one popular open source python library panda take data various format reformat load tabular representation data presenting row column format panda reformat load include csv excel pickle javascript object notation json panda also data analysis manipulation feature use throughout module loading data simple example pull csv file specified url load data panda stored panda data frame panda documentation data frame described general labeled size mutable tabular structure potentially heterogeneously typed column helpful way think data frame leave spreadsheet sql table like table spreadsheet data frame row also known instance column also known attribute shape property data frame describes number row column column data frame series series labeled array serious store data type learn data structure panda see panda imitation along data load data frame row label column label row label known index column label known column loaded data csv file header row column created first line file change behavior however column name source file pas parameter performing data analysis important make sure using correct data type many case panda correctly infer correct data type load data move domain knowledge access domain expert often identify data type issue use either type info function obtain information column type shown example correct data type need figure case often numeric column could missing data could single text value example car data set number door two three four five analyzed data convert column correct data type using panda part one section see part two review describe data'],\n",
       " ['Mod03_Sect03_part2.mp4',\n",
       "  'back continue exploring describe data data readable format perform descriptive statistic data better understand descriptive statistic help gain valuable insight data effectively data prepare ml model look discus important first descriptive statistic organized different category overall statistic include number row number column data set information relates dimension data important example indicate many feature lead high dimensionality poor model performance attribute statistic another type descriptive statistic specifically numeric attribute used get better sense shape attribute includes property like mean standard deviation variance minimum maximum value need look relationship one variable consider multivariate statistic mostly relate correlation relationship attribute case multiple variable feature might want look correlation important identify correlation attribute high correlation two attribute sometimes lead poor model performance feature closely correlated used model predict response variable could problem example model loss might converge minimum state aware highly correlated feature data set mean median two different measure describing extent data clustered around value position mean useful method understanding data data symmetrical however skewed contains outlier median tends provide better metric understanding data relates central tendency instance outlier large value mean skewed one way would serve accurate representation value truly centered median affected outlier way talk outlier soon statistic available viewed numerical data using method describe also message calculate mean median others also view statistic single multiple column even group data specific value categorical attribute look frequency attribute value data set information give idea inside categorical variable diagram show car data set made several categorical value buying mate lug boot safety class safety either low medium high describe function see three unique value low frequent looking class column appears top value four unacc stand unaccounted account value might suggest imbalance get variable also categorical type look class distribution see whether class imbalance data set balance data mark disproportionate ratio class instance data set made credit card transaction tenth percent labeled fraud case algorithm might learn well enough predict example credit card fraud visualization could help gain insight data might aware otherwise histogram often good visualization technique seeing overall behavior particular feature histogram answer question like feature data normally distributed many peak data skewness particular feature using histogram data visualization value bend taller peak histogram indicate common value numerical feature use density plot box plot addition get idea inside particular feature like histogram visualization help answer question like range data peak data outlier special feature answering question help understand data better also help decide need specialized data preprocessing box plot method graphically depicting group numerical data quartile two miracle variable feature data set might want look relationship scatter plot good way identify special relationship among variable case left diagram sulfate alcohol two numerical variable suppose want show relationship variable use scatterplot help visualize plot scattered around correlation among might high data scattered however might find relatively positive relationship two variable scatter plot matrix help look relationship multiple different feature panda easily create scatter plot matrix based column want look example three column give pairwise scatter plot two column scatter plot might want identify special region particular subset data could fit example relationship alcohol sulfate quality plot value good poor quality wine like example plotting give idea useful particular variable using classification problem part two section see part three review correlation takeaway section'],\n",
       " ['Mod03_Sect03_part3.mp4',\n",
       "  'back review find correlation data set quantify linear relationship among variable seeing scatter plot correlation matrix good tool situation conveys strong weak linear relationship among numerical variable correlation go high one low minus one correlation one mean two cool feature perfectly correlated like saying proportional x correlation two variable like saying proportional minus x linear relationship quantified correlation correlation zero mean linear relationship mean relationship indication linear relationship two variable however looking number always straightforward often easier view number represented color look heat map highest number one dark green minus one dark brown color give positive negative direction also show strong correlation use seaborn heat map function show correlation matrix looking chart correlation citric acid fixed acidity would expected wine citric acid contributes acidity wine however much correlation fixed acidity ph ph measurement strength acid present fix acidity measure quantity particular data set appear correlation key takeaway section module include point first step get data format used easily panda popular python library working data descriptive statistic help gain insight data use visualization examine data set detail section see next'],\n",
       " ['Mod03_Sect04_part1.mp4',\n",
       "  'section section going look feature engineering feature engineering one impactful thing improve machine learning model well look two thing help make model successful first feature selection second feature extraction process creating feature feature selection sele relevant feature discard rest apply feature selection prevent redundancy irrelevance existing feature also use limit number feature help prevent overfitting feature extraction build valuable information raw data reformatting combining transforming primary feature new one process continues yield new data set consumed model achieve goal diagram show feature extraction cover range activity dealing missing data converting text data numerical data although list exhaustive give idea data handling needed get data useful state many task different job working data want make sure data correct format consistently represented correctly spelled among task example combine data extract data multiple column could also remove column together specific machine learning need convert text column numerical value also need decide handle outlier potentially rescale data next look common task section machine learning algorithm work best numerical data need make sure column data contain numeric data converting encoding might need make several pass data sheet encode example might variability text value row contain medium med value categorical data ordered want encode text numerical value capture ordinal relationship say data showing maintenance cost might encode low medium two high three high four made sure categorical data uniform use tool like skykit learn panda encode data categorical data order need break data multiple column help make sure introduce ordinal relationship data example suppose assigned value one first color red assigned next value say blue model could interpret blue important red blue higher numeric value encoding data multiple column feature better way think new feature like checkbox consider example three feature generated value one indicates instance feature like color section see next'],\n",
       " ['Mod03_Sect04_part2.mp4',\n",
       "  'back continue exploring feature engineering reviewing clean data set addition converting string data numerical data need clean data set several potential problem area encoding string data make sure string consistent also need make sure variable use consistent scale example one variable describes number door car scale probably two eight another variable describes number car particular type sold state california scale probably thousand data item might also capture one variable single value instance suppose data set includes variable combine safety maintenance single variable safe high maintenance need train machine learning system variable also single variable two separate variable might also encounter data set missing data variable data set include outlier cover technique dealing situation section might find data missing example column data set could missing data data collection error maybe data collected particular feature data collection process underway missing data make difficult accurately interpret relationship related feature target variable regardless data ended missed important deal issue unfortunately machine learning algorithm ca handle missing value automatically need use human intelligence update missing value data meaningful relevant problem python library data manipulation include function finding missing data decide drop impute missing value question answered part better understanding value came missing first place much data missing value represent within larger data set instance say missing value randomly spread throughout data set represent larger portion respective row column case imputation likely better option contrast say column row large percentage missing value case dropping entire row column would preferred imputation decide drop row missing data use function example panda drop na function drop row missing data drop specific data value using subset alternative dropping missing value impute value missing value different way impute missing value categorical value missing value usually replaced mean median frequent value numerical continuous variable missing value usually replaced mean median impute single row missing data known univariate also multiple row known multivariate look univariate example sidekick learn pewter function used cute missing value fairly small data set two missing value missing value imputed strategy mean first calculate mean mean impute mean value missing value data library include impute package provides complex way impute data example include k nearest neighbor soft cute multiple imputation chain equation others part two section see part three review work outlier data'],\n",
       " ['Mod03_Sect04_part3.mp4',\n",
       "  'back continue exploring feature engineering describing work outlier might also need clean data based outlier exist outlier point data set lie abnormal distance value always something want clean add richness data set also make harder make accurate prediction skew value normal value related feature outlier might also indicate data point actually belongs another column think outlier falling two broad category first single variation single variable univariate outlier second variation two variable multivariate outlier one common way find univariate outlier box plot box plot far data point mean variable box plot show data value within two quartile mean value outside range represented line extending box sometimes called whisker scatter plot effective way see multivariate outlier example diagram show amount sulfate alcohol collection line scatter plot quickly visualize whether multivariate two variable origin outlier likely inform deal phase pipeline possibly later feature engineering several different approach dealing outlier could delete outlier outlier based artificial error mean outlier natural introduced failure like incorrectly entered data could also transform outlier taking natural log value turn reduces variation caused extreme outlier value would reduce outlier influence overall data set finally could use mean feature impute value replace outlier value would good approach outlier caused artificial error exhaustive list describes common option extracted feature need select appropriate feature training model three main feature selection method filter method use statistical method measure relevance feature correlation target variable wrapper method measure useful subset feature training model feature measuring successful model filter faster cheaper wrapper method involve training model repeatedly rapper typically find best subset feature risk overfitting compared using subset feature filter method embedded method algorithm specific might use combination filter wrapper filter method use proxy measure instead actual model performance fast compute still capture useful feature set common measure first pearson correlation coefficient measure statistical relationship association two continuous variable second linear discriminant analysis lda used find linear combination feature separate two class third analysis variance anova used analyze difference among group mean sample finally single number tell much difference exists observed count count expect absolutely relationship filter usually le computationally intensive wrapper produce feature set tuned specific type predictive model lack tuning mean feature set filter general one rapper filter also usually lower prediction performance wrapper however filter feature set contain assumption prediction model useful exposing relationship feature many filter provide feature ranking instead explicit best feature subset cutoff point ranking chosen cross validation filter also used preprocessing step wrapper enables wrapper used larger problem wrapper method use predictive model score feature subset new subset used train model tested holdout set score subset calculated counting number mistake made holdout set error rate model rapper train new model subset computationally intensive however usually provide best performing feature set particular type model problem forward selection start feature add best model found backward selection start feature drop one time select best model embedded method combine quality filter wrapper method implemented algorithm feature selection method popular example method lasso ridge regression penalization function reduce overfitting key takeaway section module first feature engineering involves selecting best feature machine learning preprocessing give better data work better data typically provides better result two category preprocessing converting data numerical value cleaning dirty data removing missing data cleaning outlier finally handle dirty data impact model section see next'],\n",
       " ['Mod03_Sect05.mp4',\n",
       "  'back module section training section going look select model train data preprocessed point done lot clean prepare data mean data completely ready train algorithm algorithm may able work training data data frame format file format like csv commonly used play various algorithm make use optimization file format like record protobuf use many amazon sagemaker algorithm support training data csv format amazon sagemaker requires csv file header record target variable first column amazon sagemaker algorithm work best use optimized protobuf record io format training data using form allows take advantage pipe mode training algorithm support pipe mode training job stream data directly amazon using csv format target variable training data set first column left feature right target variable column evaluating model data trained lead overfitting recall overfitting turn particular data set well essentially memorizing training data rather learning relationship feature label mean model learning relationship pattern apply new data future hold split data multiple set commonly set training data validation data testing data training data includes feature label feed algorithm selected prod model use model make prediction validation data set likely notice thing want tweak tune change ready run test data set includes feature since want label actually predicted performance get test data set reasonably expect see production common split using holdout method using data training set validation test lot data split training validation test small data set use cross validation utilize much data possible still relatively good metric order choose model better kfold cross validation randomly partition data k different segment segment use rest data outside training order validation particular segment let look example five fold cross validation available training data separated five different chunk training first model using chunk training data going calculate metric test piece second model going use piece training model trained apply test thing five time use training data tested five different model different chunk test data eventually testing data point one thing note splitting data data specific order lead bias model especially true working structured data example wine data ordered quality column run model test data ordered pattern applied biasing model might also mean target missing training data typically randomizing data set prior splitting sufficient many library provide function smaller set sometimes useful use stratified sampling stratified sampling ensures training test set approximately percentage sample target class complete set internet search give many way shuffle split one easiest use train test split function sk learn amazon sage maker provides four different way train model algorithm available easily deployed aws console cli jupiter notebook container used behind scene use one amazon sagemaker built algorithm deal directly amazon sage maker supported framework provide container support deep learning framework apache mxnet tensorflow pie torch chainer also support machine learning library skykit learn spark ml providing docker image use amazon sagemaker python sdk deployed using respective amazon sagemaker sdk estimator class amazon sagemaker container image use modify advanced scenario package script algorithm use amazon sagemaker use programming language framework develop container example team work build ml model build container train host algorithm r well someone else may already developed tune model worth looking aws marketplace find available model amazon sage maker provides high performance scalable machine learn algorithm optimized speed scale accuracy supervised learning amazon sagemaker includes xgboost linear learner algorithm classification quantitative regression problem also factorization machine address recommendation time series prediction problem amazon sagemaker includes support unsupervised learning k mean clustering principal component analysis pca problem like identifying customer grouping based purchasing behavior finally selection specialized algorithm processing image deep learning task let look little closer three commonly used algorithm use case xgboost extreme gradient boosting popular efficient open source implementation gradient boosted tree algorithm gradient boosting super learning algorithm attempt accurately predict target variable combining ensemble estimate set simpler weaker model xgboost done remarkably well machine learning competition robustly handle variety data type relationship distribution large number hyperparameters tweaked tuned improved fit flexibility make xgboost solid choice problem regression classification binary ranking amazon sagemaker linear learner algorithm provides solution classification regression problem amazon sagemaker algorithm simultaneously explore different training objective choose best solution validation set also explore large number model choose best one need compare method provide solution continuous objective amazon sagemaker linear algorithm provides significant increase speed naive hyperparameter optimization technique k mean unsupervised learning algorithm attempt find discrete grouping within data member group similar possible one another different possible member group find attribute want algorithm use determine similarity train model amazon sagemaker create training job training includes url amazon bucket stored training data url bucket want store output job amazon elastic container registry path training code stored compute resource want amazon sagemaker use model training compute resource ml compute instance managed amazon sagemaker amazon sagemaker provides selection instance type optimize fit different machine learning use case instance type comprise varying combination cpu gpu memory networking capacity give flexibility choose appropriate mix resource building training deploying ml model instance type includes one instant size allowing scale resource requirement target workload key takeaway section module include split data training testing set help validate accuracy kfold cross validation help smaller data set two key algorithm supervised learning xgboost linear learner use k mean unsupervised learning use amazon sagemaker train model section hope see next'],\n",
       " ['Mod03_Sect06.mp4',\n",
       "  'back section going look hosting using model section look deploy trained model consumed application trained tuned tested model learn testing next section ready deploy model thinking looking phase order discussing deployment want test model get perform first need make inference prediction model typically requires deployment deployment testing different production although mechanic amazon sagemaker provides everything need host model simple testing evaluation request deployment handling ten thousand request two way deploy model single prediction deploy model amazon sagemaker hosting service sagemaker deploy multiple instance run model behind load balanced endpoint application call api endpoint make prediction model scale number instance based demand get prediction entire data set use amazon sagemaker batch transform instead deploying maintaining permanent endpoint sagemaker spin model perform prediction entire data set provide store result amazon shuts terminates instance useful performing batch prediction test model quickly run entire validation set model without writing code process collate individual result goal deployment phase provide managed environment host model providing inference securely low latency model deployed production monitor production data retrain model necessary newly deployed model need current production data new data accumulated time could potentially identify alternative new outcome deploying model exercise instead continuous process one click deploy model amazon ml instance automatically scale across multiple availability zone higher redundancy specify type instance maximum minimum number instance desired sagemaker take care rest launch instance deploy model set secure http endpoint application application need include api call endpoint achieve inference low latency high throughput architecture integrate new model application minute change model longer need change application code sagemaker manages production compute infrastructure behalf perform health check apply security patch conduct routine maintenance amazon cloudwatch monitoring logging trained model create endpoint either code using sagemaker console planning host single model create endpoint model planning host multiple model need create multi model endpoint endpoint provide scalable solution deploying large number model use shared serving container unable host multiple model reduces hosting cost improving endpoint utilization compared using single model endpoint also reduces deployment overhead sagemaker manages loading model memory scaling model based traffic pattern deploy machine learning model production make prediction new data need make sure apply data processing step used training request otherwise get incorrect prediction result using inference pipeline reuse data processing step model training inference without maintaining two separate copy code help ensure accuracy prediction reduces development overhead sagemaker managed service inference pipeline completely managed deploy pipeline model service installs run sequence container instance endpoint batch transform job additionally sequence feature processing inference run low latency container collated instance key takeaway section module include point deploy train model using sagemaker handle api call application perform prediction using batch transformation goal model generate prediction answer business problem sure model good result deploy production finally use endpoint support save resource multiple model deploy section see next'],\n",
       " ['Mod03_Sect07_part1.mp4',\n",
       "  'back module section look evaluate model success predicting result point trained model time evaluate model determine good job predicting target new future data future instance unknown target value need ass model perform data already know target answer use assessment proxy performance future data reason hold sample data evaluating testing important part phase involves choosing appropriate metric business situation think back earlier section problem formulation phase define business problem outcome craft business metric evaluate success model metric choose phase linked business metric much possible often high relation two metric addition considering business problem success metric type ml problem working influence model metric choose throughout rest module look example common metric used classification problem also look common metric used regression problem going start considering simple binary classification problem specific example imagine simple image recognition model labeling data either cat cat model trained use test data set held back perform prediction help examine performance model compare predicted value actual value plot value table like example start getting insight well model performed confusion matrix get high level comparison predicted class matched actual class actual label class cat identified p positive predicted label class also cat true positive good outcome model similarly actual label cat identified n negative predicted label class also cat true negative also good outcome model case model predicted correct outcome used testing data two possible outcome considered good outcome first one actual class negative got cat predicted class positive cat called false positive prediction positive incorrect finally false negative happen actual class positive got cat predicted class negative cat part one section see part two review calculating classification metric'],\n",
       " ['Mod03_Sect07_part2.mp4',\n",
       "  'back continue exploring evaluate model diagram show confusion matrix two different model performed data tell one better better good question ask mean better better mean making sure find cat even mean get many false positive better mean making sure model accurate difficult see looking two trying several model using multiple fold hundred data point compare need calculate metric first metric sensitivity sometimes referred recall hit rate true positive rate sensitivity percentage positive identification cat example represents percentage cat correctly identified calculate sensitivity take number true positive number posit identification cat divide total number actual cat example cat cat correctly identified cat specificity sometimes referred selectivity true negative rate specificity percentage negative correctly identified cat example number image cat correctly identified cat calculate specificity take number negative divide total number actual negative example number cat correctly identified divided total number actual cat mean example cat identified cat metric model knowing business goal make easier decide model use model would choose wanted make sure identify many cat possible would good answer concerned many false positive concerned incorrectly identified cat model would choose wanted make sure identified animal cat model might work scenario would depend many false negative tolerate classification patient heart disease model would best get interesting fun website might get bad reputation ca identify cat correctly trying diagnose patient focus probably different important understand making decide model use also metric help make decision part two section see part three start looking threshold'],\n",
       " ['Mod03_Sect07_part3.mp4',\n",
       "  'back continue exploring evaluate model classification model going return probability target value input belonging target class convert value class need determine threshold use might think could change lower higher improve result seen sensitivity specificity correctly incorrectly identifying class changing threshold impact outcome going take look visualize receiver operating characteristic graph also known roc graph summarizes confusion matrix threshold produced build one calculate plot sensitivity true positive rate false positive rate graph threshold value calculate fal right subtracting specificity one plot point draw line dotted black line mean sensitivity true positive rate equal false positive rate point one one mean correctly identified cat also incorrectly identified cat bad point line mean proportion correctly classified sample proportion incorrectly classified sample point represents zero true positive false positive model high sensitivity low false positive rate usually goal considered better line threshold recording closer towards top left corner data two model could plot roc curve model compare however tedious another graph use look next another evaluation metric use area curve receiver operator curve also known auc roc auc part area plotted line auc higher mean model better predicting cat cat cat cat use auc quickly compare model four number confusion matrix calculate model accuracy also known score adding correct prediction dividing number total number prediction though accuracy widely used metric classification problem limitation metric effective lot true negative case data set think cat cat example accuracy based true negative say model good predicting cat case might feel confident model ability predict cat roll production lead example important make sure metric choose model evaluation aligns business goal think credit card fraud example case using accuracy main metric probably good idea lot true negative high true negative number might hide fact model ability identify case identify true positive ideal credit card company probably unacceptable le almost perfect performance identifying fraud case would drive customer away would opposite want achieve business standpoint two metric often used situation first one precision essentially remove negative prediction precision proportion positive prediction actually correct taking true positive dividing true positive plus false positive cost false positive high particular business situation precision might good metric think classification model identifies email message spam case want model label email message spam thus prevent user seeing message actually legitimate consider example model need predict whether patient terminal illness using precision evaluation metric account false negative model model successful crucial fall asleep predict absence illness patient actually illness sensitivity would better metric use situation always need one score combine precision sensitivity together give one number quantifies overall performance particular ml algorithm consider using score class imbalance preserve equality precision sensitivity dealing regression problem case common metric use evaluate model including mean squared error mean squared error frequently used general purpose saw classification metric determine prediction model compare prediction actual outcome specifically take difference prediction actual value square difference sum square difference observation skykit learn use mean squared error function directly metric library metric use linear model r squared trained model performed batch transformation test data calculated use metric help tune model could select different set feature train model retrain model ask better model metric help inform could also use different data retrain model feature remember cross validation earlier module finally could tune parameter model subject next section key takeaway section module evaluate model need data model seen could either holdout set could use k fold cross validation different machine learning model use different metric classification use confusion matrix auc roc generate regression use mean squared section see next'],\n",
       " ['Mod03_Sect08.mp4',\n",
       "  'back module section section going take look tune model hyperparameters improve model performance recall earlier module hyperparameters thought knob tune machine learning algorithm improve performance looking explicitly tuning model time look specifically different type hyperparameters perform hyperparameter optimization couple different category hyperparameters first kind model hyperparameters help define model example consider neural network computer vision problem case additional attribute architecture need defined like filter size pooling stride padding second kind optimizer hyperparameters relate model learns pattern based data used neural network model type hyperparameters include optimizers like gradient descent stochastic gradient descent also include optimizers use momentum like atom initialize parameter weight method like xavier initialization initialization third kind data hyperparameters relate attribute data include attribute define different data augmentation technique like cropping resizing problem often used enough data enough variation data tuning hyperparameters labor intensive traditionally done manually someone domain experience related hyperparameter use case person would please select hyperparameters based intuition experience would train model score validation data process would repeated achieved satisfactory result manual process always thorough efficient way tuning hyperparameters sage maker perform automated hyperparameter tuning amazon sagemaker automatic model tuning find best version model multiple training job data set using algorithm hyperparameter range specify chooses hyperparameter value result model performs best measured metric choose us gaussian process regression predict hyper perimeter value might effective improving fit also us bayesian optimization balance exploring hyperparameter space exploiting specific hyperparameter value appropriate importantly automatic model tuning used algorithm sagemaker deep learning framework bring algorithm container suppose want solve binary classification problem fraud data set goal maximize area auc curve metric algorithm training linear learner algorithm model know value learning rate beta beta epoxy use train best model find best value hyperparameters specify range value sagemaker hyperparameter tuning search find combination value result training job performs best measured objective metric chose example sagemaker hyperparameter tuning launch training job use hyperparameter value range specified return training job highest auc hyperparameter might necessarily improve model advanced tool building machine solution considered part scientific method process build complex machine learning system like deep learning neural network exploring possible combination impractical improve optimization use following guideline create hyperparameters first instead using hyperparameters limit number hyperparameters one think would give good result range value hyperparameters choose search significantly affect success hyperparameter optimization although might want specify large range cover every possible value hyperparameter get better result limiting search small range value get best metric value within part range consider limiting range part hyperparameter tuning sagemaker attempt figure hyperparameters log scaled linear initially assumes hyperparameters linear scaled log scaled might take time sagemaker discover know hyperparameter log scaled convert improve hyperparameter optimization running hyperparameter tuning job currently get work done quickly tuning job improves successive round experiment typically running one training job time achieves best result least amount compute time say distributed training job run multiple instance case hyperparameter tuning us last reported objective metric instance training job value objective metric training job design distributed training job report objective metric want gone end end process training tuning machine learning model worth talking amazon sagemaker autopilot service help find good model little effort input part autopilot create job supply test training target autopilot analyze data select appropriate feature train tune model document metric find best model based provided data result include winning model metric notebook use investigate result although using autopilot remove need data save time feature selection model tuning key takeaway section module include point first model tuning important finding best solution business problem hyper parameter tuned model optimizer data sagemaker perform automatic hyperparameter tuning finally overall model development accelerated using autopilot see next one'],\n",
       " ['Mod03_WrapUp.mp4',\n",
       "  'time review module wrap knowledge check module learned formulate problem business request obtain secure data machine learning build jupiter notebook using amazon sagemaker outline process evaluating data explain data need preprocessed use open source tool examine prep data use amazon sage maker train host machine learning model use cross validation test performance ml model use hosted model inference create amazon sagemaker hyperparameter tuning job optimize model effectiveness concludes module see next'],\n",
       " ['Mod04_Intro.mp4',\n",
       "  'module aws academy machine learning module going look forecasting start introduction forecasting look time series data different kind data going look amazon forecast service help simplify building forecast end module able describe business problem solved forecast describe challenge working time series data list step required create forecast using amazon forecast use amazon forecast make prediction see next'],\n",
       " ['Mod04_Sect01.mp4',\n",
       "  'section get started reviewing forecasting use case forecasting important area machine learning important many opportunity predicting future outcome based historical data many opportunity involve time component however time component add additional information also make time series problem difficult handle comp type prediction think time series data falling two broad category first type univariate data mean one variable second one multivariate data mean one variable several common pattern time series data first pattern trend trend get pattern value increasing decreasing staying time seasonal pattern reflect time year month day pattern cyclical pattern similar seasonal pattern pattern repeat like large retail sale event happens time year finally change data time appear random discernible pattern many us forecasting use forecasting marketing application sale forecasting demand projection could also used inventory management system anticipate required inventory level forecasting energy consumption help predict energy needed weather forecasting system used government commercial application agriculture section see next'],\n",
       " ['Mod04_Sect02_part1.mp4',\n",
       "  'back section going focus processing time series data different type data using far time series data data captured chronological sequence defined period time introducing time machine learning model positive impact model derive meaning change data point time time tends correlated mean dependency data point mixed result forecasting dealing regression problem regression assumes data point independent need develop method dealing data dependence increase validity prediction addition time series data add related data augment forecasting model example suppose want make prediction retail sale could include information product sold item identification sale price along number unit sold per time period third type data metadata data set instance say retail data set might want include metadata like brand name genre music video group result better data work multiple data source face challenge handling timestamp data observe difference timestamp format challenge incomplete data however might able infer missing data case example say data contains month day year observe whether data seems sequence month number database repeating could add year knew data started could infer future year based order data much timestamp data stored utc format data check timestamp local universal time sometimes timestamp represent time think example suppose database car serviced garage timestamp indicate time car arrived completed picked indicate final entry entered system say trying model hourly caloric intake patient however daily data need adjust target time scale also data might timestamps could way extrapolate time series depending data domain example might wavelength measurement vector within image final note remember daylight saving different around world also daylight saving time might even occur twice year time zone common real world forecasting problem missing value raw data missing value make harder model generate forecast primary example retail situation demand forecasting item go stock sale day zero forecast generated based zero sale value forecast incorrect many reason value marked missing missing value occur transaction also occur possible measurement error example service monitored certain data working correctly another example measurement could happen correctly retail primary example inability take correct measurement situation demand forecasting mean demand equal sale day several way calculate missing data first method forward fill us last known value missing value building idea moving average us average last known value calculate missing value backward fill us next known value missing value danger using future calculate past bad forecasting method also known look ahead avoided interpolation us equation calculate missing value also use zero fill often used retail missing sale data calculated missing data represents order day would wise investigate happened case want fill missing value might get data different frequency example might sale data includes exact timestamp sale recorded inventory data contains year month day inventory level data different frequency pet data compatible question might need downsample sampling moving time le time example show could converting hourly data set daily data set downsampling need decide combine value previous case sale data summing quantity make sense data temperature might want find average understanding data help decide best course action opposite sampling upsampling move le time final grade time problem upsampling extremely difficult achieve case suppose want upsample sale data daily sale hourly sale unless data source reference would able case need thing perhaps match frequency another time series might irregular time series specific domain knowledge would help case need careful make conversion retail example best create single order day specified hour temperature could copy daily temperature hourly slot use formula calculate curve data science outlier mix positive negative attribute true time series data suppose examining sale data order unusually high number item might want include forecast calculation order size might never repeated removing outlier anomaly known smoothing smoothing data help deal outlier anomaly reason might consider smoothing first data preparation move error value could also remove outlier might also want smooth data generate feature visualization could smooth data reduce noise plot important understand smoothing data impact might outcome might reduce noise create better model equally important question could smoothing compromise model model expecting noisy data also able smooth data part one section see part two review time series specific challenge tool algorithm help u wrangle data'],\n",
       " ['Mod04_Sect02_part2.mp4',\n",
       "  'back continue exploring wrangling time series data seasonality data kind repeating observation frequency observation stable example sale typically see higher sale end quarter fourth quarter consumer retail see even higher sale fourth quarter aware data multiple type seasonality data set many time incorporate seasonality information forecast instance localized holiday good example sale charge show total revenue generated arcade strong correlation number computer science doctor awarded u correlation mean causation disagree see source chart many correlation plotted site none make sense data careful seeing acting correlation meaning real world experiment generate two random time series data set number find low correlation introduce slope data set see strong correlation need know stable system level ability stationery inform much expect system past behavior inform future behavior system low stability wo successful predicting future often want determine trend time series would series trend difficult compare another series also adjusted trend trend might dominate value series could lead overestimate correlation two like discussed previously autocorrelation one special problem face time series data seen machine learning problem goal building ml model make sure separating signal noise auto correlation form noise separate observation independent time series autocorrelation might overstate accuracy model produced algorithm look module help correct autocorrelation factor along seasonality influence model select produce forecast algorithm handle seasonality autocorrelation others panda developed financial data analysis mind good handling time series data first set index appendix data frame date time use date time select data use range contain partial date also extract date part year month weekday name grouping resampling task pentas function finally panda give insight autocorrelation information panda time series refer pendous documentation one task building forecasting application choose appropriate algorithm choice algorithm determined type data set using feature data set amazon forecast support five algorithm others algorithm handle data slightly different characteristic example take auto regressive integrated moving average also known arima remove auto correlation influence pattern observation take exponential smoothing also known ets algorithm useful data set seasonality find algorithm amazon forecast documentation key takeaway section module include time series data sequence data includes time element make different regular data set time challenge include dealing different time format handling missing data sampling sampling smoothing dealing seasonality week yearly cycle avoiding bad correlation penis excellent time series support function dealing time five algorithm used amazon forecast arima deep ar plus ets npts profit section see next'],\n",
       " ['Mod04_Sect02_part3.mp4',\n",
       "  'fine back section look use amazon forecast create predictor generate forecast generate forecast apply machine learning development pipeline seen throughout course still need data need import much data historical data related data want basic evaluation feature engineering use data train meet requirement amazon forecast train predictor need choose algorithm sure algorithm best data amazon forecast choose select automl algorithm also need select domain data sure best fit also select custom domain domain specific type data require trained model use model make forecast using input data set group generated forecast query forecast also export bucket amazon finally encrypt data forecast exporting overall process working amazon forecast import historical related data amazon forecast inspects data identifies key data select appropriate algorithm us algorithm train optimize custom model produce predictor create forecast applying predictor data set retrieve forecast aws management console export forecast comma delimited file also use api aws cli command create retrieve forecast work amazon forecast select domain working domain ranging retail web traffic also custom option everything else selecting domain improve efficiency predictor domain specific type data supply build predictor example retail domain expects data item identifier timestamp observation number sale item specified timestamp example data need provide ret demand forecast time series need time transaction took place ideally utc format item id item many item sold metadata item might include category item color attribute link back time series data item id item metadata typically change related data creating useful forecast could include price promotion data link back item must include timestamp item id example data need provide web traffic forecast time series need web page id number page view per month timestamp related data creating useful forecast could include page category navigation content category also need geographic identifier web plan metadata might also need provide region sale promotion information amazon forecast predictor use algorithm train model use model make forecast using input data set group help get started amazon forecast provides predefined algorithm arima deep ar plus ets pt profit also use automl feature try algorithm see one best predicting data prepare data training machine learning typically hold back data use validate score model data hold back usually random sample available data time series data must process data differently correlation time import data amazon forecast break training test data set diagram show training data used train model tested data held back specify multiple back test window split data multiple time train model use metric determine model give best result default back test window one change amazon forecast split data setting back test window offset parameter create predictor set value algorithm use default value trained model need measure accuracy learn next first amazon forecast evaluation metric weighted quantile loss w quantile loss amazon forecast creates forecast provides probabilistic prediction three distinct quantiles prediction quantiles show much uncertainty associated forecast quantile predicts time true value le predicted value example suppose retailer want forecast product demand winter glove sell well fall winter say sufficient storage space cost invested capital high price overstocked winter glove concern might use quantile order relatively low number winter know forecast overestimate demand winter glove time sold winter glove time quantile predicts time true value le predicted value continuing winter glove example say know moderate amount demand glove concerned overstocked might choose use quantile order glove quantile predicts time true value le predicted value suppose determine stocked glove result large amount lost revenue example cost selling glove extremely high cost invested capital low case might choose use quantile order glove amazon forecast also calculates associated loss error quantile weighted quant calculate far forecast certain quantile actual demand either direction lower w quantile loss metric mean model forecast reliable root mean square error rmse another method evaluating reliability forecast like w quantile loss rmse calculates far forecasted value actual test data rmse find actual target value data set forecasted value time period square difference example show calculate rmse rmse value represents standard deviation prediction error test good forecast validity error mostly size many outlier lower rmse metric indicate model forecast reliable example web tell might use accuracy metric evaluate forecast retailer want predict demand sale particular brand shoe input sale record brand amazon forecast create predictor predictor provides forecasted demand pair value shown weighted quantile loss value indicate time fewer pair sold time fewer pair sold time fewer pair sold retailer use value determine level inventory hold base decision assessment risk wo able fulfill order excess inventory key takeaway section module include use amazon forecast train use model time series data specific schema define domain retail capacity planning use custom schema need supply least time series data also provide metadata related data add information model supervised machine learning problem data split training testing data take new account time element use rmse w quantile loss metric evaluate effic model see next one'],\n",
       " ['Mod04_WrapUp.mp4',\n",
       "  'back time review module wrap module learned describe business problem solved amazon forecast describe challenge working time series data list step required create forecast using amazon forecast use amazon forecast make prediction participating see next module'],\n",
       " ['Mod05_Intro.mp4',\n",
       "  'back awsacademy machine learning module great topic today computer vision module start overview computer vision space learn use case terminology next explore detail analyzing image managed service amazon web service aws finally look use phone customized data set performing object detection end module able describe use case computer vision describe amazon management machine learning service available image analysis list step required prepare custom data set object detection describe amazon sagemaker ground truth used prepare custom data set finally use amazon recogn perform facial detection see next'],\n",
       " ['Mod05_Sect01_ver2.mp4',\n",
       "  'back section going introduce computer vision computer vision exciting space machine learning think computer vision automated extraction information digital image using computer vision machine identify people place thing image accuracy human level greater speed efficiency computer vision often built deep learning model automates extraction analysis classification understanding useful information single image sequence image image data take many form single image sequence view multiple camera data computing power algorithm advanced last year led increase capability easier access computer vision technology computer vision used primary use case computer vision use image facial recognition improve public safety home security way authenticate access personal device also use automatically classify image content management analysis autonomous driving partly enabled computer vision technology safety feature car lane detection collision medical image analysis computer vision improve accuracy speed patient medical diagnosis result better treatment outcome life expectancy patient finally manufacturing computer vision incorporated robotics improve quality assurance operational efficiency example probably think computer vision problem broken area content recognition identifying thing image classification problem complex one several layer picture represented breakfast lunch dinner would classification food answer depends model use perform classification model must trained training data provides algorithm data learn say model trained picture different type food might expect image category milk peach mashed potato chicken nugget salad train model different image could classify object tray cutlery napkin instead work image might want know kind object image location object object detection provides image category object located image set coordinate defining location box surrounding image known bounding box bounding box detection typically top left width height coordinate surrounding image use coordinate application object detected image confidence number usually associated object percentage indicates probability object belongs specific class confidence level important want determine action based object detection especially detection application case action significance object segmentation also known semantic segmentation like object detection go detail get fine boundary detected object basically inference predicting pixel image application require object segmentation include autonomous vehicle advanced computer human interaction object segmentation problem field computer vision wo covering course add another dimension computer vision get data work capture movement people object referred instance example detect people enter leave frame also deal moving camera use case computer vision building detection tracking analyze shopper behavior retail store studying path person follows use face analysis understand detail shopper average age range gender distribution expressed emotion without identifying another computer vision use case also analyze image identify action using motion example activity delivering package dancing looking image baseball player example image could include capturing batter accuracy picture pitching style type pitch slow ball slider others inning batter performance versus specific picture manager could use data coach player improve performance coach also use data game make game time decision say want initiate various action based speed baseball leaving bat trajectory hit calculated model could lead audio visual warning possible foul ball crowd could result preemptive alarm hit high probability home run mean event following home run could automated playing music setting firework home run hit home team wrap section key takeaway section first covered computer vision automated extra information image divide computer vision two distinct area image analysis analysis image analysis includes object classification detection segmentation analysis includes instance tracking action recognition motion estimation see next'],\n",
       " ['Mod05_Sect02_part1_ver2.mp4',\n",
       "  'back section explore image analysis detail part two take closer look analysis start introduce main amazon service using amazon recognition amazon recognition computer vision service based deep learning use add image analysis application many us amazon recognition including creating image library amazon recognition make image stored video searchable discover object scene appear use amazon recognition build user verification system application confirm user identity comparing live image reference image amazon recognition interprets emotional expression happy sad surprise also interpret demographic information facial image gender amazon recognition also detect inappropriate content image stored video finally amazon recognition recognize extract text content image go quick note security need check application build using amazon recognition fall regulatory restriction defined field country security compliance amazon recognition shared responsibility aw customer information topic see aws compliance page amazon recognition aws managed service managed service amazon host machine learning model maintains api scale meet demand benefit set model constantly learn improve also focus building application use api optionally training service understand unique need various resource use access interact amazon recognition apis sdks command aws command line interface also known aws cli language supported sdks include javascript python ruby java go j finally amazon recognition integrates w service example need storage use amazon simple storage service authentication authorization use aws identity access management also known diagram illustrates image search feature user take picture get information real estate property viewing first user take picture mobile device user initiate search cause application go amazon configured call service right n occurs case bucket pass path new object aws lambda lambda function called us amazon recognition sdk call service amazon recognition analyzes image detects aspect property creates label pass information back lambda object formatted javascript object notation lambda store label confidence score amazon elasticsearch service also known amazon e application user identify aspect property using object detected image example architecture system check uploaded image inappropriate content like previous example processing begin user uploads content first user uploads image amazon second bucket configured call lambda function object written bucket third lambda call amazon recognition via sdk amazon recognition analyzes image inappropriate content sends response back lambda fourth content appropriate content approved fifth content appropriate content sent manual inspection finally content approved notification sent user final use case system analyzes feed sentiment analysis first camera capture sent back office application typically application like us amazon kinesis stream second application us sdk send amazon recognition analysis visual sentiment extracted along attribute age third discovered attribute sent amazon kinesis fourth lambda function extract data stream fifth data written next data loaded amazon redshift regular basis finally tool like amazon quick site used generate report data amazon recognition designed integrate application api sdks api operation provided detecting label face recognizing celebrity detecting unsafe image perform prediction provide service image object amazon upload byte stream image image jpeg png format amazon recognition process image performs prediction return json object result amazon recognition performs prediction often return multiple label label confidence level confidence level indicates likely label found image like example show label also hierarchy find instance object need understand detected object image instance result amazon recognition include bounding box contains starting coordinate top left box dimension width height like example use information determine location detected object image important note finding contain confidence score use confidence score application tune response prediction higher score likely object correctly labeled part one section see part two explore facial detection'],\n",
       " ['Mod05_Sect02_part2.mp4',\n",
       "  'back continue exploring image analysis closer look facial detection facial detection us model tuned perform prediction specifically detecting face facial feature facial detection many feature standard object detection bounding box coordinate box surrounding face detected include value representing conf bounding box contains face list attribute found face beard appears male female also confident score attribute also detect physical emotion like whether person smiling frowning important understand classification based visual clue might represent actual emotion person facial landmark component face eye typical landmark also include x coordinate quality describes brightness sharpness face pose describes rotation face inside image confidence feature provided detected feature remember feature prediction based visual observation amazon recognition compare two image determine contain person comparison require source target image result include face found include information matching face confidence score indicate likely prediction amazon recognition also search known face use feature need train model providing collection image use train model detect people image provide find known face first create collection add face collection amazon recognition perform facial recognition image provide return typical information like bounding box coordinate confidence score associate face image specify image id external image id request parameter could file name image another id create create collection use search face image operation search face collection return data contains array face matched information includes bounding box confidence score external image id value use id value link back source image learned facial detection feature amazon recognition summary guideline discussed far amazon recognition send text human face capture bounding box show face found also detect attribute position eye nose mouth detect emotion quality detection landmark might appear item associated confidence score higher score mean model greater confidence detection gender inferred image inferred identity similarly emotion also determined image might reflect subject actual emotional state apply facial recognition responsibly facial recognition never used way violates individual right including right privacy also never used make autonomous decision scenario require human analyze example suppose bank us tool like amazon recognition financial application verify customer identity bank always clearly disclose use technology ask customer approve term condition information topic see aws web page fact facial recognition artificial intelligence well explain use amazon recognition process video perform processing stored video stream stored uploaded stored bucket type detection start operation search people face label celebrity text inappropriate content amazon recognition publishes completion status topic amazon simple notification service also known amazon sn route message subscriber durability best practice route message message amazon simple q service amazon sqs application monitor sqsq completion start operation corresponding get operation retrieving result call get detection result return array label contain information label found label information includes label image detection also includes timestamp label detected second start addition stored video also use amazon recognition detect recognize face streaming typical use case detecting known face stream amazon recognition us amazon kinesis stream receive process stream analysis result output amazon recognition kinesis data stream read client application amazon recognition provides stream processor called create stream processor use start manage analysis streaming use amazon recognition streaming application must implement resource first need kinesis stream send streaming amazon recognition next need amazon recognition stream processor manage streaming analysis finally need kinesis data stream consumer read analysis result amazon recognition sends data stream want find face need create collection process creating collection still image amazon recognition place json frame record analyzed frame kinesis output stream amazon recognition analyze every frame passed kinesis stream frame record sent kinesis data stream contains information stream fragment frame frame fragment face recognized frame also includes status information stream processor wrap quick summary amazon recognition computer vision service based deep learning easily add image analysis application amazon ignition detect face sentiment text unsafe content library search image amazon recognition integrated aws service see next'],\n",
       " ['Mod05_Sect03_part1.mp4',\n",
       "  'section look preparing custom data set computer vision detect custom object one challenge using model find image trained find though amazon recognition trained ten million image ca detect object trained example consider eight heart playing card run card amazon recognition result show various attribute however none label playing card eight heart want amazon recognition detect image problem domain must train model image section learn train amazon recognition image problem domain though focus using amazon recognition encounter similar process use model training computer vision algorithm recognize image requires large input data set practical organization many machine learning problem today solved training existing model use managed service like amazon recognition custom label like machine learning process need train amazon recognition recognizes scene object specific domain need training data set test dat contain labeled image image need label use amazon recognition custom label simplify labeling task example provides ui labeling image includes feature use draw bounding box around image also help find object scene unique business need use classify image detect object within image say want identify specific machine part image turbochargers torque converter could collect picture kind machine part use train model amazon recognition custom label also includes automated machine learning capability handle machine learning process provide training image service automatically load inspect data select correct machine learning algorithm train model provide model performance metric finish training model evaluate custom model performance test set image test set comparison model prediction versus label assigned also detailed performance metric review start using model immediately image analysis iterate retrain new version image refine model start using model track prediction correct mistake use feedback data retrain new model version improve performance label image diagram show typical process training computer vision model includes amazon recognition custom label feature step detail process developing custom model analyze image requires time expertise resource often take month complete also require thousand ten thousand hand labeled image model enough data make accurate decision take month generate gather data require large team laborer prepare use machine learning amazon recognition custom label build existing capability amazon recognition already trained ten million image across many category instead thousand image upload small set training image specific use case typically use hundred image use aws management console upload training image image already labeled amazon recognition custom label begin training model label image directly labeling interface use amazon sagemaker ground truth label shortly amazon recognition custom label work best use different model different domain example need detect machine part plant health use two different model image select training similar image used inference use image use various lighting condition background resolution ideally training image mirror image want perform detection use source like production work best documentation includes additional guideline image type whether jpegs pngs property like image size resolution part one section see part two review create training data set'],\n",
       " ['Mod05_Sect03_part2.mp4',\n",
       "  'back continue exploring analysis reviewing create training data set data set contain information needed train test amazon recognition custom label model image label bounding box use image amazon upload computer part process train model dat least two label least image per label image data set must labeled mentioned earlier use amazon recognition custom label console amazon sagemaker ground truth label image train amazon recognition custom label model image must labeled label indicates image contains object seen concept mentioned earlier data set need least two defined label also image must least one assigned label identifies object seen concept image apply label image whole label known image level label useful identifying scene concept want detect example one image show beach scene ko olina island oahu u state hawaii train model detect beach add beach label applies entire image also apply label specific area image contain object want detect example want model detect amazon echo device must identify different type echo device image model need information device located image need corresponding label identifies type device nation known localization information location device expressed bounding box example object bounding box image show bounding box surround amazon echo dot image also contains amazon echo without bounding box output labeling process manifest file manifest file image level label typically contains label class name along metadata image labeled object detection manifest contains information labeled image bounding box identifies object image along label bounding box belongs mentioned amazon sagemaker ground truth time well look might help sagemaker ground truth build high quality training data set machine learning model use create data set need labeling provide detailed instruction need labeled submit job decide process image create label data set use worker amazon mechanical turk service vendor company internal workforce machine learning use label data set output sagemaker ground truth train model also use amazon recognition custom label speaker ground truth use active learning automate labeling input data active learning machine learning technique identifies data labeled worker sagemaker ground truth functionality called automated data labeling automated data labeling reduce time cost take label data set compared using human worker use automated labeling incur amazon sagemaker training inference yes said use machine learning label image use machine learning talk work sagemaker ground truth start automated data labeling job selects random sample input data object sends human worker label data returned sagemaker ground truth us data validation data validate model trained automated data labeling speaker ground truth run batch transform job using validated model inference validation data batch inference produce confidence score quality metric object validation data automated labeling determines confidence score object produced step five meet required threshold determined step confidence score meet threshold expected quality automatic labeling exceeds requested level accuracy object considered automatically labeled step produce data set unlabeled data confidence score sagemaker ground truth selects data point low confidence score data set sends human worker additional labeling sagemaker ground truth us existing human label data additional human label data train new model process repeated data set fully labeled another stopping condition met example automatic labeling stop meet budget human annotation recommend using automated data labeling large data set minimum number object allowed automated data labeling however strongly suggest providing minimum object part two section see part three review evaluate improve model'],\n",
       " ['Mod05_Sect03_part3.mp4',\n",
       "  'back continue exploring analysis reviewing create test data set final step train model identify test data set use test data set validate evaluate model performance performing inference image test data set compare result labeling information training data set create test data set alternatively use amazon recognition custom label split training data set two data set using split split mean data used training used testing define training test data set amazon recognition custom label automatically train model service automatically load inspects data select correct machine learning algorithm train model provides model performance metric charge amount time model take train data set contains image label take longer train training complete evaluate performance model testing amazon recognition custom label predicts test image contains custom label confidence score value quantifies certainty model prediction classification problem result mapped confusion matrix true positive model correctly predicts presence custom label test image predicted label also ground truth label image example amazon recognition custom label correctly return cat label cat present image false positive incorrectly predicts presence custom label test image predicted label ground truth label image example amazon recognition custom label return cat label cat label ground truth image false negative model predict custom label present image ground truth image includes label example amazon recognition custom label return cat custom label image contains cat true negative model correctly predicts custom label present test image example amazon recognition custom label return cat label image contain cat console provides access true positive false positive false negative value image test data set prediction result used calculate various metric label aggregate metric entire test set emission apply prediction model make bounding box level bounding box metric calculated bounding box test image regardless whether box prediction ground truth help amazon recognition custom label provides various metric example view summary metric evaluation metric label also provides precision metric label average precision metric entire test data set precision proportion positive result correctly classified amazon recognition custom label provides average recall metric label average recall metric entire test data set recall fraction test set label correctly classified using previous example cat would many cat correctly classified service also provides average model performance score label average model performance score entire test data set score combine precision recall together give one number quantifies overall performance particular machine learning algorithm might use score class imbalance also want preserve equality precision sensitivity higher value mean better model performance recall precision satisfied accuracy model start using part three section see part review evaluate improve model'],\n",
       " ['Mod05_Sect03_part4_ver2.mp4',\n",
       "  'back continue exploring analysis reviewing evaluate improve model general improve quality model larger quantity better quality data use training image clearly show object seen include many thing interested bounding box around object use training image show object fully visible hidden object make sure training test data set match type image eventually run inference object training example like logo provide bounding box around logo test image image represent scenario want localize object reducing false positive often result better position reduce false positive first check increasing confidence threshold enables keep correct pre eliminating false positive increasing confidence threshold eventually result diminishing gain precision recall given model next check see need add additional class training example detecting cat often dog flagged cat add dog label training data set along image dog got false positive effectively helping model learn predict cat new training image might find model confused two custom label cat dog test image label cat predicted labeled dog vice versa case first check mislabeled image training test set also adding training image reflect confusion help retrain model learn better discriminate cat dog reducing false negative consulting better recall reduce false negative first lower confidence threshold improve recall also use better example model variety object image appear finally split label two class easier learn example instead good cooky bad cooky might want good cooky burnt cooky broken cooky help model learn unique concept better satisfied performance model make available use starting console using code model running perform inference aws cli sdk call api specify amazon resource name amazon recognition custom label model want use amazon resource name also known arn also specify image want model make prediction provide input image image byte array encoded image byte object custom label returned array custom label object custom label represents single object seen concept found image custom label includes label object seen concept found image also includes bounding box object found image bounding box coordinate object located source image coordinate value ratio overall image size finally custom label includes confidence score represents confident amazon recognition custom label accuracy label bounding box training model calculates threshold value determines prediction label true default detect custom label operation return label value le model calculated threshold value filter returned label specify value min confidence greater model calculated threshold get model calculated threshold model training result amazon recognition custom label console get label regardless confidence specify min confidence value zero find confidence value returned detect custom label operation low consider retraining model restrict number custom label returned detect custom label operation specifying max result input parameter return result sorted highest confidence lowest confidence key takeaway section module model must trained specific domain want analyze looking turbochargers need many picture turbochargers train set custom labeling specific business case looked custom labeling process tool use want object detected need label image create bounding box object use amazon sagemaker ground truth build training data set model also use machine learning label image see next'],\n",
       " ['Mod05_WrapUp_ver2.mp4',\n",
       "  'time summarize main point module module learned describe use case computer vision describe amazon management machine learning service available image analysis list step required prepare custom data set object detection describe amazon sagemaker ground truth used prepare custom data set use amazon recognition perform facial detection concludes introduction computer vision see next'],\n",
       " ['Mod06_Intro.mp4',\n",
       "  'module aws academy machine learning introduction natural language processing module introduce natural language processing also known nlp section includes description major challenge faced nlp overall development process nlp application review five aws service use speed development patience completing module able describe nlp use case solved using managed amazon ml service describe managed amazon ml service available nlp let get started'],\n",
       " ['Mod06_Sect01.mp4',\n",
       "  'get started reviewing natural language processing mean natural language processing also known nlp explain nlp consider example nlp amazon alexa alexa work device amazon echo record word recording speech sent amazon server analyzed efficiently amazon break phrase individual sound connects database containing pronunciation various word find word closely correspond combination individual sound amazon identifies important word make sense task carry corresponding function instance alexa notice word like outside temperature open weather alexa skill amazon server send information back device alexa speaks nlp term general set business computational problem solve machine learning ml however nlp system predate machine learning example speech text older pre smartphone cell phone used nlp screen reader many nlp system use form machine learning nlp considers hierarchical structure language word lowest layer hierarchy group word make phrase next level phrase make sentence ultimately sentence convey idea nlp system face several significant challenge look challenge next language precise word different meaning based word surround known context often word phrase multiple meaning example consider term weather could weather colloquial meaning english sick could say wonderful weather outside mean weather condition outside good phrase oh really could convey surprise disagreement many thing depends context inflection main challenge nlp one challenge discovering structure text one first task nlp application break text meaningful unit word phrase sentence another challenge labeling data system convert text data must apply label representing various part speech every language require different labeling scheme match language grammar nlp also face challenge representing context word meaning depend heavily context nlp system need way represent large challenge many contact difficult convert context form computer understand finally although grammar defines structure language application grammar indescribably large scope handling variation language used human major challenge nlp system machine learning large impact apply nlp range problem common application include search application google human machine interaction like alexa sentiment process marketing political campaign social research based medium analysis chatbots mimic human speech application apply machine learning development pipeline seen throughout course developing nlp solution first task formulate problem collect label data nlp collecting data consists breaking text meaningful subset labeling set feature engineering major part nlp application process get complicated dealing highly irregular unstructured text example say building application classify document need able distinguish word common term different meaning labeling data nlp domain sometimes also called tagging labeling process assign individual text string different part speech specialized tool use nlp labeling first task nlp application convert text data analyzed convert text removing word needed analysis input text example word removed leave phrase sample text removing stop word normalize text converting similar word common form example word run runner ran running different form word run normalize instance word block text using stemming limitation process limitation group different form word single term limitation version word run would group instance form single term run stemming hand remove character stemming algorithm considers unnecessary stunning might work run example form ran might recognized form word run normalized text standardize removing word dictionary using analysis example could remove acronym slang special character natural language toolkit also known nltk python library provides function removing stop word normalizing text another first step creating nlp system convert text data collection data frame nlp library provide function assist process example show using word tokenize function nltk library cleaned text loaded data frame apply one nlp model create feature couple common model first model known bag word simple model capturing frequency word document model creates key word value key number time word occurs document second model term frequency inverse document frequency also known tf idf term frequency count many time word appears document inverse document frequency number time word occurs group document two value used together calculate weight word word frequently appear many document lower many established model nlp field example show bag word model bag word vector model vector model convert sentence phrase vector mathematical object record directionality magnitude example simple sentence converted vector frequency word recorded word value appears twice sentence bag word often used classify document different category also used derive attribute feed nlp application sentiment analysis three broad category text analysis first classification text similar classification system seen course text provides input process extract feature send feature machine learning algorithm interacts classifier model infers classification many application text matching example autocorrect spelling grammar checking based text matching algorithm edit distance also known leavenstein distance frequently used derive relationship different word phrase text using process called resolution several nlp system provide python library deriving relationship one biggest challenge nlp describe context text consider example user searching term tablet word tablet least two distinct meaning search engine need know meaning user mind search engine rely commonly used context term qualified example adding another term like medicine computing search process extracting entity known named entity recognition ner model following first identify noun phrase using dependency chart part speech tagging classify phrase using classification algorithm word vac finally disambiguate entity using knowledge graph example using ner extract entity titanic north atlantic text named entity extracted use knowledge graph extract meaning knowledge graph combine subject matter tease machine learning drive meaning amazon recommendation engine example knowledge graph main point remember section first nlp predates machine learning use ml workflow seen module nlp main use case nlp search query analysis human machine interaction marketing social research nlp complicated language lack precision see next'],\n",
       " ['Mod06_Sect02.mp4',\n",
       "  'back section review five management machine learning service use various use case service simplify process creating machine learning application start looking amazon transcribe use amazon transcribe recognize speech audio file produce transcription recognize specific voice audio file create customized vocabulary term specialized particular domain also add transcription service application integrating websockets internet protocol use communication application amazon transcribe common use case amazon transcribe first medical professional record note amazon transcribe capture spoken note text also production organization generate subtitle automatically could also done real time live feed add closed captioning medium company use amazon transcribe capture label content feed content amazon comprehend analysis last company record customer service sale call transcribe analyze result training strategic opportunity amazon poly convert text lifelike speech input either file file formatted speech synthesis markup language ssml ssml markup language used provide special instruction speech sound example want introduce pause flow speech add ssml tag instructs amazon poly pause two word also output speech amazon poly vorbis pcm audio stream format amazon poly eligible use certain regulated workload example eligible use u health insurance portability accountability act hipaa amazon poly also eligible use payment card industry data security standard pci ds common use case amazon poly first example major news company using amazon poly generate vocal content directly written story also embedded mapping apis developer add voice application language training company used amazon poly create system learning new language finally animator used add voice character amazon translate create experience application create system read document one language render store another language also use part document analysis system amazon translate fully integrated machine learning service amazon comprehend amazon transcribe amazon poly integration extract named entity sentiment key phrase integrating amazon comprehend create multilingual subtitle amazon transcribe speak translated content amazon poly common use case amazon translate first use building international website use amazon translate quickly globalize website amazon translate also used develop multilingual chatbots chatbots used create interface application amazon translate create chatbot speaks multiple language another use case software localization localization major cost software aimed global audience amazon translate software development time significantly reduce cost localizing software final example use case international medium management company manage medium global audience used amazon translate reduce cost localization amazon comprehend implement many nlp technique reviewed earlier module extract key entity perform sentiment analysis tag word part speech common use case amazon comprehend first example analyzing legal medical document legal insurance medical organization used amazon comprehend perform many nlp function reviewed module another use mobile app analysis mobile app developer use amazon comprehend look pattern usage apps design improvement financial fraud detection another use case amazon banking financial institution used examine large data set financial transaction uncover fraud look pattern illegal transaction finally used content management medium content company use amazon comprehend tag content analysis management amazon lex add human language front end application amazon lex let use conversational engine amazon alexa automatically increase capacity amazon lex solution creating aws lambda function scale demand also store log file conversation analysis common use case amazon lex first use case building front end interface inventory management sale voice interface becoming common company used amazon lex add chatbots inventory sale application another use amazon lex creating customer service interface human like voice application quickly becoming standard many customer service application amazon lex reduce time take develop chatbots increase quality amazon used develop interactive assistance combining amazon lex ml service creating sophisticated assistance many different industry final example use case querying database language amazon lex combined aws database service create sophisticated data analysis application language interface main point take away module first amazon transcribe automatically convert spoken language text amazon poly convert written text spoken language amazon translate create transl language amazon comprehend automates many nlp use case reviewed module finally amazon lex create interface application see next'],\n",
       " ['Mod06_WrapUp.mp4',\n",
       "  'back time review module wrap summary module learn describe nlp use case solved using managed amazon ml service describe managed ml service available nlp good job see next module'],\n",
       " ['Mod07_Sect01.mp4',\n",
       "  'module course wrap congratulation completing aws academy machine learning course take minute review learned go going start review learned course learned describe machine learning implement machine learning pipeline use amazon machine learning service forecasting computer vision natural language processing well done although course designed prepare become certified aws certified machine learning specialty review continue work towards certification aws certification help build credibility confidence validating cloud expertise industry recognized credential also help organization identify skilled professional lead cloud initiative using aws must earn passing score taking proctored exam earn aws certification receiving passing score receive certification credential aws certification publish list service feature covered certification exam however exam guide exam list current topic area objective covered exam exam guide found prepare aws certification exam web page required update certification recertify every year aws certification recertification page detail information slide current june however exam frequently updated also detail regarding exam available topic tested exam subject change aws certified machine learning specialty mean select justify appropriate machine learning approach given business problem also identify appropriate u service implement machine learning solution finally design implement scalable cost optimized reliable secure machine learning solution sitting aws certified machine learning specialty exam recommend following knowledge experience first one two year experience developing architecting running ml deep learning workload aws cloud experience include basic hyperparameter optimization working machine learning deep learning framework also able express intuition behind basic ml algorithm finally able follow best practice model training addition best practice deployment operation congratulation completing aws academy machine learning course']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yakeNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raj\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\raj\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\n",
      "     ---------------------------------------- 60.2/60.2 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jellyfish in c:\\users\\raj\\anaconda3\\lib\\site-packages (from yake) (0.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\raj\\anaconda3\\lib\\site-packages (from yake) (1.21.5)\n",
      "Requirement already satisfied: tabulate in c:\\users\\raj\\anaconda3\\lib\\site-packages (from yake) (0.8.10)\n",
      "Requirement already satisfied: networkx in c:\\users\\raj\\anaconda3\\lib\\site-packages (from yake) (2.8.4)\n",
      "Collecting segtok\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: click>=6.0 in c:\\users\\raj\\anaconda3\\lib\\site-packages (from yake) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\raj\\anaconda3\\lib\\site-packages (from click>=6.0->yake) (0.4.5)\n",
      "Requirement already satisfied: regex in c:\\users\\raj\\anaconda3\\lib\\site-packages (from segtok->yake) (2022.7.9)\n",
      "Installing collected packages: segtok, yake\n",
      "Successfully installed segtok-1.5.11 yake-0.4.8\n"
     ]
    }
   ],
   "source": [
    "pip install yake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracting key phrases and topics\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to extract the key phrases and topics from the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer/code here\n",
    "import yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phrases(text):\n",
    "    extractor = yake.KeywordExtractor()\n",
    "    keywords = extractor.extract_keywords(text)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = []\n",
    "\n",
    "for file, text in transcripts:\n",
    "    keywords.append([file, [phrase for phrase, score in extract_phrases(text)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Mod01_Course Overview.mp4',\n",
       "  ['machine learning pipeline',\n",
       "   'machine learning section',\n",
       "   'machine learning',\n",
       "   'machine learning problem',\n",
       "   'amazon machine learning',\n",
       "   'machine learning service',\n",
       "   'certified machine learning',\n",
       "   'machine learning engineer',\n",
       "   'implement machine learning',\n",
       "   'machine learning specialty',\n",
       "   'learning section learn',\n",
       "   'machine learning model',\n",
       "   'natural language processing',\n",
       "   'role machine learning',\n",
       "   'statistic machine learning',\n",
       "   'learning section describes',\n",
       "   'learning machine learning',\n",
       "   'field machine learning',\n",
       "   'machine learning technology',\n",
       "   'machine learning professional']],\n",
       " ['Mod02_Intro.mp4',\n",
       "  ['business problem solved',\n",
       "   'solve business problem',\n",
       "   'challenge face completing',\n",
       "   'traditional software development',\n",
       "   'software development method',\n",
       "   'development method ready',\n",
       "   'problem solved machine',\n",
       "   'aws academy machine',\n",
       "   'deep learning part',\n",
       "   'business problem describe',\n",
       "   'academy machine learning',\n",
       "   'introduce machine learning',\n",
       "   'solved machine learning',\n",
       "   'recognize machine learning',\n",
       "   'machine learning deep',\n",
       "   'tool challenge face',\n",
       "   'part artificial intelligence',\n",
       "   'data scientist identify',\n",
       "   'learning deep learning',\n",
       "   'problem describe machine']],\n",
       " ['Mod02_Sect01.mp4',\n",
       "  ['machine learning subset',\n",
       "   'machine learning model',\n",
       "   'train machine learning',\n",
       "   'email message spam',\n",
       "   'learning practitioner spend',\n",
       "   'building machine perform',\n",
       "   'machine deep learning',\n",
       "   'machine learning',\n",
       "   'intelligence machine learning',\n",
       "   'layer artificial neuron',\n",
       "   'spam deep learning',\n",
       "   'machine learning practitioner',\n",
       "   'task deep learning',\n",
       "   'algorithm statistical model',\n",
       "   'deep learning practitioner',\n",
       "   'definition machine learning',\n",
       "   'machine learning understand',\n",
       "   'machine learning capability',\n",
       "   'artificial intelligence machine',\n",
       "   'discus machine learning']],\n",
       " ['Mod02_Sect02.mp4',\n",
       "  ['machine learning program',\n",
       "   'aws deep racer',\n",
       "   'reinforcement learning model',\n",
       "   'learning supervised learning',\n",
       "   'learning reinforcement learning',\n",
       "   'learning program trained',\n",
       "   'machine learning supervised',\n",
       "   'machine learning reinforcement',\n",
       "   'problem machine learning',\n",
       "   'machine learning problem',\n",
       "   'unsupervised machine learning',\n",
       "   'machine learning',\n",
       "   'type machine learning',\n",
       "   'problem supervised learning',\n",
       "   'supervised learning problem',\n",
       "   'deep learning model',\n",
       "   'supervised learning model',\n",
       "   'fraud machine learning',\n",
       "   'variable machine learning',\n",
       "   'machine learning application']],\n",
       " ['Mod02_Sect03.mp4',\n",
       "  ['training data model',\n",
       "   'overfitting training data',\n",
       "   'time train model',\n",
       "   'train model training',\n",
       "   'model training data',\n",
       "   'age birth month',\n",
       "   'training data perform',\n",
       "   'data train model',\n",
       "   'model overfitting training',\n",
       "   'model underfitting training',\n",
       "   'feature engineering training',\n",
       "   'model data feature',\n",
       "   'training evaluating model',\n",
       "   'underfitting training data',\n",
       "   'training data evaluation',\n",
       "   'data model performs',\n",
       "   'train model process',\n",
       "   'data source data',\n",
       "   'underfitting model model',\n",
       "   'model model overfitting']],\n",
       " ['Mod02_Sect04.mp4',\n",
       "  ['jupiter notebook jupiter',\n",
       "   'notebook jupiter lab',\n",
       "   'notebook jupiter notebook',\n",
       "   'machine learning framework',\n",
       "   'jupiter notebook open',\n",
       "   'notebook open source',\n",
       "   'environment jupiter notebook',\n",
       "   'amazon sage maker',\n",
       "   'machine learning',\n",
       "   'host jupiter notebook',\n",
       "   'running jupiter notebook',\n",
       "   'task jupiter notebook',\n",
       "   'jupiter notebook frequently',\n",
       "   'jupiter notebook code',\n",
       "   'notebook frequently machine',\n",
       "   'open source machine',\n",
       "   'source machine learning',\n",
       "   'jupiter lab flexible',\n",
       "   'jupiter lab manages',\n",
       "   'learning task jupiter']],\n",
       " ['Mod02_Sect05.mp4',\n",
       "  ['machine learning problem',\n",
       "   'challenge machine learning',\n",
       "   'machine learning',\n",
       "   'formulate machine learning',\n",
       "   'operating machine learning',\n",
       "   'substantial machine learning',\n",
       "   'sophisticated machine learning',\n",
       "   'machine learning lot',\n",
       "   'machine learning knowledge',\n",
       "   'machine learning add',\n",
       "   'machine learning capability',\n",
       "   'service machine learning',\n",
       "   'machine learning challenge',\n",
       "   'machine learning solution',\n",
       "   'solve machine learning',\n",
       "   'machine learning business',\n",
       "   'managed service machine',\n",
       "   'learning lot poor',\n",
       "   'learning add sophisticated',\n",
       "   'learning capability application']],\n",
       " ['Mod02_WrapUp.mp4',\n",
       "  ['artificial intelligence machine',\n",
       "   'part artificial intelligence',\n",
       "   'stage developing machine',\n",
       "   'discussing challenge machine',\n",
       "   'learned recognize machine',\n",
       "   'intelligence machine learning',\n",
       "   'artificial intelligence describe',\n",
       "   'intelligence describe artificial',\n",
       "   'describe artificial intelligence',\n",
       "   'type problem machine',\n",
       "   'terminology identify machine',\n",
       "   'machine learning',\n",
       "   'defining machine learning',\n",
       "   'machine learning fit',\n",
       "   'machine learning applies',\n",
       "   'machine learning pipeline',\n",
       "   'developing machine learning',\n",
       "   'machine learning application',\n",
       "   'challenge machine learning',\n",
       "   'machine learning summary']],\n",
       " ['Mod03_Intro.mp4',\n",
       "  ['machine learning pipeline',\n",
       "   'machine learning model',\n",
       "   'machine learning problem',\n",
       "   'learning pipeline applied',\n",
       "   'academy machine learning',\n",
       "   'entire machine learning',\n",
       "   'handling machine learning',\n",
       "   'type machine learning',\n",
       "   'machine learning build',\n",
       "   'host machine learning',\n",
       "   'performance machine learning',\n",
       "   'focus supervised learning',\n",
       "   'learning build jupiter',\n",
       "   'learning problem machine',\n",
       "   'problem machine learning',\n",
       "   'back aws academy',\n",
       "   'amazon sagemaker outline',\n",
       "   'amazon sagemaker host',\n",
       "   'create amazon sagemaker',\n",
       "   'amazon sagemaker hyperparameter']],\n",
       " ['Mod03_Sect01.mp4',\n",
       "  ['machine learning model',\n",
       "   'machine learning pipeline',\n",
       "   'data machine learning',\n",
       "   'machine learning problem',\n",
       "   'credit card transaction',\n",
       "   'data set based',\n",
       "   'reduction number customer',\n",
       "   'make prediction section',\n",
       "   'machine learning',\n",
       "   'machine learning make',\n",
       "   'machine learning activity',\n",
       "   'machine learning purpose',\n",
       "   'machine learning repository',\n",
       "   'reminder machine learning',\n",
       "   'requirement machine learning',\n",
       "   'solved machine learning',\n",
       "   'unsupervised machine learning',\n",
       "   'term machine learning',\n",
       "   'irvine machine learning',\n",
       "   'processed machine learning']],\n",
       " ['Mod03_Sect02_part1.mp4',\n",
       "  ['source data set',\n",
       "   'launch training job',\n",
       "   'data machine learning',\n",
       "   'target answer prediction',\n",
       "   'credit card fraud',\n",
       "   'open source data',\n",
       "   'predict credit card',\n",
       "   'training job amazon',\n",
       "   'relational database service',\n",
       "   'data source training',\n",
       "   'source training data',\n",
       "   'training data set',\n",
       "   'database service amazon',\n",
       "   'intended business outcome',\n",
       "   'source target fraud',\n",
       "   'desired output subsequently',\n",
       "   'training set launch',\n",
       "   'set launch training',\n",
       "   'job amazon sagemaker',\n",
       "   'file system amazon']],\n",
       " ['Mod03_Sect02_part2.mp4',\n",
       "  ['aws glue data',\n",
       "   'glue data catalog',\n",
       "   'catalog aws glue',\n",
       "   'aws glue',\n",
       "   'set aws glue',\n",
       "   'extract transform load',\n",
       "   'store aws glue',\n",
       "   'aws glue service',\n",
       "   'aws glue run',\n",
       "   'aws glue console',\n",
       "   'aws glue training',\n",
       "   'table aws glue',\n",
       "   'process aws glue',\n",
       "   'aws glue fully',\n",
       "   'aws glue consists',\n",
       "   'retries aws glue',\n",
       "   'aws glue serverless',\n",
       "   'aws glue api',\n",
       "   'interface aws glue',\n",
       "   'environment aws glue']],\n",
       " ['Mod03_Sect02_part3.mp4',\n",
       "  ['obtain data multiple',\n",
       "   'account cloud trail',\n",
       "   'aws account cloud',\n",
       "   'cloud trail log',\n",
       "   'infrastructure cloud trail',\n",
       "   'access resource make',\n",
       "   'retain account activity',\n",
       "   'account activity related',\n",
       "   'account activity including',\n",
       "   'cloud trail service',\n",
       "   'history aws account',\n",
       "   'aws cloud trail',\n",
       "   'aws account activity',\n",
       "   'activity aws account',\n",
       "   'make easy obtain',\n",
       "   'monitor retain account',\n",
       "   'auditing aws account',\n",
       "   'aws account feature',\n",
       "   'glue make easy',\n",
       "   'store finally make']],\n",
       " ['Mod03_Sect03_part1.mp4',\n",
       "  ['correct data type',\n",
       "   'data frame row',\n",
       "   'visualize analyze data',\n",
       "   'frame row label',\n",
       "   'load data frame',\n",
       "   'column data frame',\n",
       "   'label row label',\n",
       "   'data type load',\n",
       "   'type load data',\n",
       "   'panda data frame',\n",
       "   'data frame panda',\n",
       "   'row label column',\n",
       "   'column label row',\n",
       "   'row column column',\n",
       "   'label column label',\n",
       "   'spreadsheet data frame',\n",
       "   'data frame describes',\n",
       "   'data frame series',\n",
       "   'data format type',\n",
       "   'column correct data']],\n",
       " ['Mod03_Sect03_part2.mp4',\n",
       "  ['feature data set',\n",
       "   'scatter plot matrix',\n",
       "   'data set information',\n",
       "   'data set made',\n",
       "   'poor model performance',\n",
       "   'relationship scatter plot',\n",
       "   'plot box plot',\n",
       "   'set information give',\n",
       "   'column scatter plot',\n",
       "   'variable scatter plot',\n",
       "   'set made credit',\n",
       "   'scatter plot good',\n",
       "   'column data set',\n",
       "   'set information relates',\n",
       "   'imbalance data set',\n",
       "   'instance data set',\n",
       "   'create scatter plot',\n",
       "   'pairwise scatter plot',\n",
       "   'car data set',\n",
       "   'data set balance']],\n",
       " ['Mod03_Sect03_part3.mp4',\n",
       "  ['relationship indication linear',\n",
       "   'quantify linear relationship',\n",
       "   'weak linear relationship',\n",
       "   'linear relationship quantified',\n",
       "   'indication linear relationship',\n",
       "   'set quantify linear',\n",
       "   'citric acid fixed',\n",
       "   'heat map highest',\n",
       "   'seaborn heat map',\n",
       "   'heat map function',\n",
       "   'back review find',\n",
       "   'strong weak linear',\n",
       "   'dark green minus',\n",
       "   'citric acid contributes',\n",
       "   'matrix good tool',\n",
       "   'set detail section',\n",
       "   'wine citric acid',\n",
       "   'dark brown color',\n",
       "   'map function show',\n",
       "   'expected wine citric']],\n",
       " ['Mod03_Sect04_part1.mp4',\n",
       "  ['data multiple column',\n",
       "   'multiple column feature',\n",
       "   'section machine learning',\n",
       "   'machine learning model',\n",
       "   'improve machine learning',\n",
       "   'specific machine learning',\n",
       "   'machine learning algorithm',\n",
       "   'text column numerical',\n",
       "   'make model successful',\n",
       "   'task section machine',\n",
       "   'encode text numerical',\n",
       "   'thing improve machine',\n",
       "   'extraction process creating',\n",
       "   'selection prevent redundancy',\n",
       "   'capture ordinal relationship',\n",
       "   'introduce ordinal relationship',\n",
       "   'feature extraction process',\n",
       "   'feature selection prevent',\n",
       "   'engineering feature engineering',\n",
       "   'selection sele relevant']],\n",
       " ['Mod03_Sect04_part2.mp4',\n",
       "  ['row missing data',\n",
       "   'drop row missing',\n",
       "   'clean data set',\n",
       "   'data set missing',\n",
       "   'set missing data',\n",
       "   'variable describes number',\n",
       "   'single row missing',\n",
       "   'missing data drop',\n",
       "   'missing data make',\n",
       "   'missing data data',\n",
       "   'drop impute missing',\n",
       "   'missing data variable',\n",
       "   'missing data decide',\n",
       "   'underway missing data',\n",
       "   'finding missing data',\n",
       "   'find data missing',\n",
       "   'continuous variable missing',\n",
       "   'column data set',\n",
       "   'data set includes',\n",
       "   'function finding missing']],\n",
       " ['Mod03_Sect04_part3.mp4',\n",
       "  ['feature selection method',\n",
       "   'selection start feature',\n",
       "   'feature training model',\n",
       "   'method embedded method',\n",
       "   'method filter method',\n",
       "   'selection method filter',\n",
       "   'method involve training',\n",
       "   'wrapper method measure',\n",
       "   'wrapper filter method',\n",
       "   'filter wrapper method',\n",
       "   'variable wrapper method',\n",
       "   'plot box plot',\n",
       "   'selection method popular',\n",
       "   'wrapper method involve',\n",
       "   'problem wrapper method',\n",
       "   'box plot box',\n",
       "   'filter method embedded',\n",
       "   'cheaper wrapper method',\n",
       "   'wrapper method implemented',\n",
       "   'holdout set error']],\n",
       " ['Mod03_Sect05.mp4',\n",
       "  ['amazon sagemaker algorithm',\n",
       "   'amazon sagemaker linear',\n",
       "   'amazon sagemaker includes',\n",
       "   'problem amazon sagemaker',\n",
       "   'amazon sage maker',\n",
       "   'sagemaker amazon sagemaker',\n",
       "   'amazon sagemaker amazon',\n",
       "   'learning amazon sagemaker',\n",
       "   'amazon sagemaker provides',\n",
       "   'format amazon sagemaker',\n",
       "   'test data set',\n",
       "   'amazon sagemaker train',\n",
       "   'model amazon sagemaker',\n",
       "   'column amazon sagemaker',\n",
       "   'amazon sagemaker container',\n",
       "   'learning algorithm attempt',\n",
       "   'linear learner algorithm',\n",
       "   'class amazon sagemaker',\n",
       "   'objective amazon sagemaker',\n",
       "   'amazon sagemaker sdk']],\n",
       " ['Mod03_Sect06.mp4',\n",
       "  ['prediction entire data',\n",
       "   'entire data set',\n",
       "   'deploy model amazon',\n",
       "   'host multiple model',\n",
       "   'data processing step',\n",
       "   'model create endpoint',\n",
       "   'sagemaker deploy multiple',\n",
       "   'amazon sagemaker batch',\n",
       "   'deploy multiple instance',\n",
       "   'endpoint make prediction',\n",
       "   'single prediction deploy',\n",
       "   'model amazon sagemaker',\n",
       "   'service sagemaker deploy',\n",
       "   'make inference prediction',\n",
       "   'production make prediction',\n",
       "   'amazon sagemaker hosting',\n",
       "   'prediction deploy model',\n",
       "   'multiple model deploy',\n",
       "   'application perform prediction',\n",
       "   'application code sagemaker']],\n",
       " ['Mod03_Sect07_part1.mp4',\n",
       "  ['predicted label class',\n",
       "   'cat predicted class',\n",
       "   'class actual label',\n",
       "   'actual label class',\n",
       "   'similarly actual label',\n",
       "   'label class cat',\n",
       "   'good outcome model',\n",
       "   'comparison predicted class',\n",
       "   'predicted class matched',\n",
       "   'class matched actual',\n",
       "   'matched actual class',\n",
       "   'happen actual class',\n",
       "   'reason hold sample',\n",
       "   'performed confusion matrix',\n",
       "   'determine good job',\n",
       "   'model metric choose',\n",
       "   'label cat identified',\n",
       "   'future instance unknown',\n",
       "   'review calculating classification',\n",
       "   'predicting result point']],\n",
       " ['Mod03_Sect07_part2.mp4',\n",
       "  ['cat correctly identified',\n",
       "   'correctly identified cat',\n",
       "   'total number actual',\n",
       "   'divide total number',\n",
       "   'choose wanted make',\n",
       "   'number actual cat',\n",
       "   'correctly identified divided',\n",
       "   'correctly identified calculate',\n",
       "   'negative correctly identified',\n",
       "   'number cat correctly',\n",
       "   'identified divided total',\n",
       "   'image cat correctly',\n",
       "   'cat cat correctly',\n",
       "   'identify cat correctly',\n",
       "   'percentage cat correctly',\n",
       "   'identified animal cat',\n",
       "   'percentage negative correctly',\n",
       "   'cat identified cat',\n",
       "   'concerned incorrectly identified',\n",
       "   'cat divide total']],\n",
       " ['Mod03_Sect07_part3.mp4',\n",
       "  ['false positive rate',\n",
       "   'true positive rate',\n",
       "   'sensitivity true positive',\n",
       "   'cat cat cat',\n",
       "   'lot true negative',\n",
       "   'positive false positive',\n",
       "   'true positive false',\n",
       "   'positive rate false',\n",
       "   'rate false positive',\n",
       "   'email message spam',\n",
       "   'identify true positive',\n",
       "   'dividing true positive',\n",
       "   'true positive dividing',\n",
       "   'positive dividing true',\n",
       "   'true positive ideal',\n",
       "   'taking true positive',\n",
       "   'false positive high',\n",
       "   'positive rate graph',\n",
       "   'positive rate point',\n",
       "   'equal false positive']],\n",
       " ['Mod03_Sect08.mp4',\n",
       "  ['distributed training job',\n",
       "   'sagemaker hyperparameter tuning',\n",
       "   'automatic model tuning',\n",
       "   'metric training job',\n",
       "   'training tuning machine',\n",
       "   'result training job',\n",
       "   'training job performs',\n",
       "   'tuning job improves',\n",
       "   'hyperparameter tuning job',\n",
       "   'training job data',\n",
       "   'training job time',\n",
       "   'process training tuning',\n",
       "   'multiple training job',\n",
       "   'instance training job',\n",
       "   'objective metric training',\n",
       "   'launch training job',\n",
       "   'return training job',\n",
       "   'training job highest',\n",
       "   'training job run',\n",
       "   'training job design']],\n",
       " ['Mod03_WrapUp.mp4',\n",
       "  ['wrap knowledge check',\n",
       "   'learned formulate problem',\n",
       "   'formulate problem business',\n",
       "   'problem business request',\n",
       "   'business request obtain',\n",
       "   'request obtain secure',\n",
       "   'build jupiter notebook',\n",
       "   'outline process evaluating',\n",
       "   'open source tool',\n",
       "   'source tool examine',\n",
       "   'tool examine prep',\n",
       "   'sage maker train',\n",
       "   'maker train host',\n",
       "   'cross validation test',\n",
       "   'validation test performance',\n",
       "   'hyperparameter tuning job',\n",
       "   'tuning job optimize',\n",
       "   'learning build jupiter',\n",
       "   'sagemaker outline process',\n",
       "   'train host machine']],\n",
       " ['Mod04_Intro.mp4',\n",
       "  ['time series data',\n",
       "   'working time series',\n",
       "   'series data list',\n",
       "   'challenge working time',\n",
       "   'aws academy machine',\n",
       "   'academy machine learning',\n",
       "   'business problem solved',\n",
       "   'list step required',\n",
       "   'step required create',\n",
       "   'data list step',\n",
       "   'forecasting start introduction',\n",
       "   'start introduction forecasting',\n",
       "   'describe business problem',\n",
       "   'describe challenge working',\n",
       "   'machine learning module',\n",
       "   'module aws academy',\n",
       "   'simplify building forecast',\n",
       "   'building forecast end',\n",
       "   'problem solved forecast',\n",
       "   'required create forecast']],\n",
       " ['Mod04_Sect01.mp4',\n",
       "  ['time series data',\n",
       "   'series problem difficult',\n",
       "   'opportunity predicting future',\n",
       "   'component add additional',\n",
       "   'year month day',\n",
       "   'year finally change',\n",
       "   'area machine learning',\n",
       "   'predicting future outcome',\n",
       "   'future outcome based',\n",
       "   'outcome based historical',\n",
       "   'add additional information',\n",
       "   'problem difficult handle',\n",
       "   'difficult handle comp',\n",
       "   'increasing decreasing staying',\n",
       "   'series data falling',\n",
       "   'important area machine',\n",
       "   'machine learning important',\n",
       "   'handle comp type',\n",
       "   'comp type prediction',\n",
       "   'large retail sale']],\n",
       " ['Mod04_Sect02_part1.mp4',\n",
       "  ['time series data',\n",
       "   'time series specific',\n",
       "   'missing sale data',\n",
       "   'series data data',\n",
       "   'situation demand forecasting',\n",
       "   'retail missing sale',\n",
       "   'calculate missing data',\n",
       "   'marked missing missing',\n",
       "   'missing data case',\n",
       "   'series data suppose',\n",
       "   'point time time',\n",
       "   'missing data represents',\n",
       "   'infer missing data',\n",
       "   'case sale data',\n",
       "   'processing time series',\n",
       "   'addition time series',\n",
       "   'extrapolate time series',\n",
       "   'irregular time series',\n",
       "   'true time series',\n",
       "   'review time series']],\n",
       " ['Mod04_Sect02_part2.mp4',\n",
       "  ['time series data',\n",
       "   'series data set',\n",
       "   'include time series',\n",
       "   'set amazon forecast',\n",
       "   'handling time series',\n",
       "   'time series support',\n",
       "   'time series refer',\n",
       "   'wrangling time series',\n",
       "   'random time series',\n",
       "   'face time series',\n",
       "   'independent time series',\n",
       "   'excellent time series',\n",
       "   'panda time series',\n",
       "   'trend time series',\n",
       "   'time series autocorrelation',\n",
       "   'series support function',\n",
       "   'series refer pendous',\n",
       "   'series trend difficult',\n",
       "   'series data sequence',\n",
       "   'data set amazon']],\n",
       " ['Mod04_Sect02_part3.mp4',\n",
       "  ['time series data',\n",
       "   'quantile predicts time',\n",
       "   'data amazon forecast',\n",
       "   'predicts time true',\n",
       "   'time fewer pair',\n",
       "   'amazon forecast create',\n",
       "   'forecast time series',\n",
       "   'fewer pair sold',\n",
       "   'amazon forecast train',\n",
       "   'back test window',\n",
       "   'quantile order glove',\n",
       "   'quantile loss metric',\n",
       "   'winter glove time',\n",
       "   'weighted quantile loss',\n",
       "   'pair sold time',\n",
       "   'sold time fewer',\n",
       "   'model make forecast',\n",
       "   'forecast create predictor',\n",
       "   'model forecast reliable',\n",
       "   'demand winter glove']],\n",
       " ['Mod04_WrapUp.mp4',\n",
       "  ['back time review',\n",
       "   'business problem solved',\n",
       "   'series data list',\n",
       "   'data list step',\n",
       "   'list step required',\n",
       "   'step required create',\n",
       "   'make prediction participating',\n",
       "   'problem solved amazon',\n",
       "   'learned describe business',\n",
       "   'describe business problem',\n",
       "   'describe challenge working',\n",
       "   'challenge working time',\n",
       "   'working time series',\n",
       "   'time series data',\n",
       "   'forecast make prediction',\n",
       "   'required create forecast',\n",
       "   'solved amazon forecast',\n",
       "   'amazon forecast make',\n",
       "   'review module wrap',\n",
       "   'wrap module learned']],\n",
       " ['Mod05_Intro.mp4',\n",
       "  ['prepare custom data',\n",
       "   'custom data set',\n",
       "   'back awsacademy machine',\n",
       "   'required prepare custom',\n",
       "   'phone customized data',\n",
       "   'data set performing',\n",
       "   'customized data set',\n",
       "   'great topic today',\n",
       "   'explore detail analyzing',\n",
       "   'analysis list step',\n",
       "   'list step required',\n",
       "   'sagemaker ground truth',\n",
       "   'recogn perform facial',\n",
       "   'data set object',\n",
       "   'step required prepare',\n",
       "   'awsacademy machine learning',\n",
       "   'management machine learning',\n",
       "   'topic today computer',\n",
       "   'start overview computer',\n",
       "   'vision space learn']],\n",
       " ['Mod05_Sect01_ver2.mp4',\n",
       "  ['case computer vision',\n",
       "   'computer vision automated',\n",
       "   'computer vision technology',\n",
       "   'vision computer vision',\n",
       "   'computer vision computer',\n",
       "   'computer vision',\n",
       "   'analysis computer vision',\n",
       "   'vision technology computer',\n",
       "   'technology computer vision',\n",
       "   'computer vision improve',\n",
       "   'computer vision problem',\n",
       "   'computer vision machine',\n",
       "   'efficiency computer vision',\n",
       "   'access computer vision',\n",
       "   'introduce computer vision',\n",
       "   'computer vision exciting',\n",
       "   'enabled computer vision',\n",
       "   'manufacturing computer vision',\n",
       "   'computer vision incorporated',\n",
       "   'field computer vision']],\n",
       " ['Mod05_Sect02_part1_ver2.mp4',\n",
       "  ['amazon recognition analyzes',\n",
       "   'finally amazon recognition',\n",
       "   'result amazon recognition',\n",
       "   'amazon recognition',\n",
       "   'recognition analyzes image',\n",
       "   'recognition amazon recognition',\n",
       "   'amazon recognition amazon',\n",
       "   'image inappropriate content',\n",
       "   'amazon recognition performs',\n",
       "   'call amazon recognition',\n",
       "   'service amazon recognition',\n",
       "   'amazon recognition sdk',\n",
       "   'sdk amazon recognition',\n",
       "   'amazon recognition apis',\n",
       "   'image amazon recognition',\n",
       "   'data amazon recognition',\n",
       "   'image stored video',\n",
       "   'detected object image',\n",
       "   'amazon recognition build',\n",
       "   'amazon recognition interprets']],\n",
       " ['Mod05_Sect02_part2.mp4',\n",
       "  ['kinesis data stream',\n",
       "   'stream amazon recognition',\n",
       "   'bounding box coordinate',\n",
       "   'amazon recognition',\n",
       "   'image amazon recognition',\n",
       "   'recognition kinesis data',\n",
       "   'amazon recognition kinesis',\n",
       "   'amazon recognition stream',\n",
       "   'collection amazon recognition',\n",
       "   'recognition sends data',\n",
       "   'amazon recognition send',\n",
       "   'amazon recognition provides',\n",
       "   'application amazon recognition',\n",
       "   'result amazon recognition',\n",
       "   'observation amazon recognition',\n",
       "   'amazon recognition compare',\n",
       "   'amazon recognition financial',\n",
       "   'amazon recognition publishes',\n",
       "   'amazon recognition place',\n",
       "   'amazon recognition computer']],\n",
       " ['Mod05_Sect03_part1.mp4',\n",
       "  ['amazon recognition custom',\n",
       "   'recognition custom label',\n",
       "   'train amazon recognition',\n",
       "   'learning amazon recognition',\n",
       "   'machine learning process',\n",
       "   'training data set',\n",
       "   'amazon recognition',\n",
       "   'model amazon recognition',\n",
       "   'training computer vision',\n",
       "   'amazon recognition trained',\n",
       "   'amazon recognition detect',\n",
       "   'card amazon recognition',\n",
       "   'labeled amazon recognition',\n",
       "   'includes amazon recognition',\n",
       "   'amazon recognition recognizes',\n",
       "   'capability amazon recognition',\n",
       "   'amazon recognition result',\n",
       "   'amazon recognition encounter',\n",
       "   'shortly amazon recognition',\n",
       "   'machine learning amazon']],\n",
       " ['Mod05_Sect03_part2.mp4',\n",
       "  ['sagemaker ground truth',\n",
       "   'automated data labeling',\n",
       "   'amazon recognition custom',\n",
       "   'recognition custom label',\n",
       "   'amazon sagemaker ground',\n",
       "   'speaker ground truth',\n",
       "   'label data set',\n",
       "   'training data set',\n",
       "   'score sagemaker ground',\n",
       "   'label bounding box',\n",
       "   'human label data',\n",
       "   'worker sagemaker ground',\n",
       "   'ground truth train',\n",
       "   'labeling sagemaker ground',\n",
       "   'custom label model',\n",
       "   'ground truth build',\n",
       "   'ground truth functionality',\n",
       "   'ground truth start',\n",
       "   'ground truth run',\n",
       "   'ground truth time']],\n",
       " ['Mod05_Sect03_part3.mp4',\n",
       "  ['recognition custom label',\n",
       "   'amazon recognition custom',\n",
       "   'test data set',\n",
       "   'custom label return',\n",
       "   'entire test data',\n",
       "   'custom label test',\n",
       "   'image test data',\n",
       "   'label return cat',\n",
       "   'return cat label',\n",
       "   'presence custom label',\n",
       "   'metric entire test',\n",
       "   'custom label present',\n",
       "   'label test image',\n",
       "   'create test data',\n",
       "   'truth label image',\n",
       "   'predicts presence custom',\n",
       "   'ground truth label',\n",
       "   'label ground truth',\n",
       "   'test image predicted',\n",
       "   'training data set']],\n",
       " ['Mod05_Sect03_part4_ver2.mp4',\n",
       "  ['amazon recognition custom',\n",
       "   'recognition custom label',\n",
       "   'detect custom label',\n",
       "   'custom label operation',\n",
       "   'returned detect custom',\n",
       "   'custom label returned',\n",
       "   'model calculated threshold',\n",
       "   'custom label includes',\n",
       "   'bounding box object',\n",
       "   'object custom label',\n",
       "   'increasing confidence threshold',\n",
       "   'training data set',\n",
       "   'concept found image',\n",
       "   'custom label',\n",
       "   'default detect custom',\n",
       "   'label bounding box',\n",
       "   'bounding box training',\n",
       "   'set custom labeling',\n",
       "   'custom label cat',\n",
       "   'includes bounding box']],\n",
       " ['Mod05_WrapUp_ver2.mp4',\n",
       "  ['prepare custom data',\n",
       "   'custom data set',\n",
       "   'time summarize main',\n",
       "   'required prepare custom',\n",
       "   'data set object',\n",
       "   'summarize main point',\n",
       "   'management machine learning',\n",
       "   'machine learning service',\n",
       "   'image analysis list',\n",
       "   'analysis list step',\n",
       "   'list step required',\n",
       "   'sagemaker ground truth',\n",
       "   'recognition perform facial',\n",
       "   'step required prepare',\n",
       "   'concludes introduction computer',\n",
       "   'case computer vision',\n",
       "   'introduction computer vision',\n",
       "   'main point module',\n",
       "   'perform facial detection',\n",
       "   'facial detection concludes']],\n",
       " ['Mod06_Intro.mp4',\n",
       "  ['natural language processing',\n",
       "   'introduction natural language',\n",
       "   'introduce natural language',\n",
       "   'describe managed amazon',\n",
       "   'academy machine learning',\n",
       "   'machine learning introduction',\n",
       "   'section includes description',\n",
       "   'includes description major',\n",
       "   'description major challenge',\n",
       "   'major challenge faced',\n",
       "   'learning introduction natural',\n",
       "   'language processing module',\n",
       "   'aws academy machine',\n",
       "   'speed development patience',\n",
       "   'development patience completing',\n",
       "   'patience completing module',\n",
       "   'processing module introduce',\n",
       "   'module introduce natural',\n",
       "   'service describe managed',\n",
       "   'module aws academy']],\n",
       " ['Mod06_Sect01.mp4',\n",
       "  ['convert text data',\n",
       "   'system convert text',\n",
       "   'human machine interaction',\n",
       "   'task nlp application',\n",
       "   'form word run',\n",
       "   'inverse document frequency',\n",
       "   'system machine learning',\n",
       "   'natural language processing',\n",
       "   'removing stop word',\n",
       "   'number time word',\n",
       "   'time word occurs',\n",
       "   'form machine learning',\n",
       "   'machine learning nlp',\n",
       "   'nlp system machine',\n",
       "   'apply machine learning',\n",
       "   'feature machine learning',\n",
       "   'machine learning algorithm',\n",
       "   'data system convert',\n",
       "   'predate machine learning',\n",
       "   'system predate machine']],\n",
       " ['Mod06_Sect02.mp4',\n",
       "  ['amazon translate create',\n",
       "   'application amazon lex',\n",
       "   'amazon lex add',\n",
       "   'amazon transcribe amazon',\n",
       "   'amazon comprehend amazon',\n",
       "   'amazon poly convert',\n",
       "   'amazon transcribe capture',\n",
       "   'case amazon poly',\n",
       "   'case amazon translate',\n",
       "   'case amazon lex',\n",
       "   'case amazon transcribe',\n",
       "   'case amazon comprehend',\n",
       "   'transcribe amazon poly',\n",
       "   'comprehend amazon transcribe',\n",
       "   'application amazon translate',\n",
       "   'application amazon transcribe',\n",
       "   'language amazon translate',\n",
       "   'amazon poly create',\n",
       "   'language amazon lex',\n",
       "   'amazon poly common']],\n",
       " ['Mod06_WrapUp.mp4',\n",
       "  ['back time review',\n",
       "   'nlp good job',\n",
       "   'time review module',\n",
       "   'review module wrap',\n",
       "   'module wrap summary',\n",
       "   'wrap summary module',\n",
       "   'summary module learn',\n",
       "   'learn describe nlp',\n",
       "   'service describe managed',\n",
       "   'module learn describe',\n",
       "   'back time',\n",
       "   'time review',\n",
       "   'wrap summary',\n",
       "   'case solved',\n",
       "   'good job',\n",
       "   'amazon ml service',\n",
       "   'learn describe',\n",
       "   'managed amazon',\n",
       "   'nlp good',\n",
       "   'service describe']],\n",
       " ['Mod07_Sect01.mp4',\n",
       "  ['certified machine learning',\n",
       "   'machine learning specialty',\n",
       "   'aws certified machine',\n",
       "   'academy machine learning',\n",
       "   'machine learning solution',\n",
       "   'implement machine learning',\n",
       "   'aws academy machine',\n",
       "   'completing aws academy',\n",
       "   'congratulation completing aws',\n",
       "   'machine learning',\n",
       "   'machine learning deep',\n",
       "   'machine learning pipeline',\n",
       "   'machine learning approach',\n",
       "   'describe machine learning',\n",
       "   'amazon machine learning',\n",
       "   'secure machine learning',\n",
       "   'working machine learning',\n",
       "   'machine learning implement',\n",
       "   'learning implement machine',\n",
       "   'learning deep learning']]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating the dashboard\n",
    "([Go to top](#Capstone-8:-Bringing-It-All-Together))\n",
    "\n",
    "Use this section to create the dashboard for your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer/code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search: Bollywood Movies\n",
      "Nothing found.\n",
      "--------------------------------------------------------\n",
      "Search: service machine learning\n",
      "['Mod02_Sect05.mp4', 'Mod01_Course Overview.mp4', 'Mod02_Sect01.mp4', 'Mod02_Sect02.mp4', 'Mod02_Sect04.mp4', 'Mod02_WrapUp.mp4', 'Mod03_Sect01.mp4', 'Mod07_Sect01.mp4']\n",
      "--------------------------------------------------------\n",
      "Search: unsupervised machine learning\n",
      "['Mod02_Sect02.mp4', 'Mod03_Sect01.mp4', 'Mod01_Course Overview.mp4', 'Mod02_Sect01.mp4', 'Mod02_Sect04.mp4', 'Mod02_Sect05.mp4', 'Mod02_WrapUp.mp4', 'Mod07_Sect01.mp4']\n",
      "--------------------------------------------------------\n",
      "Search: Web development\n",
      "Nothing found.\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "while(1):\n",
    "    query = str(input('Search: '))\n",
    "    if query == 'Stop': \n",
    "        break\n",
    "    preprocessed_query = preprocess_text(query)\n",
    "    query_keywords = [phrase for phrase, score in extract_phrases(preprocessed_query)]\n",
    "    suggestedvideos = []\n",
    "    for keyword in query_keywords:\n",
    "        for k in keywords:\n",
    "            if keyword in k[1]:\n",
    "                if k[0] not in suggestedvideos:\n",
    "                    suggestedvideos.append(k[0])\n",
    "    if len(suggestedvideos) != 0:\n",
    "        print(suggestedvideos)\n",
    "    else:\n",
    "        print('Nothing found.')\n",
    "    print('--------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b71a13339a0be9489ff337af97259fe0ed71e682663adc836bae31ac651d564e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
